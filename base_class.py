# -*- coding: utf-8 -*-

import os, time, shutil, pathlib, argparse
import numpy as np
import optuna
import traceback
from tqdm import tqdm

import pathlib
current_dir = pathlib.Path(__file__).resolve().parent
from dataset import plot_log, util
from transformer import get_train_valid_test, base_dataset
from model import define_model, my_callback, lr_finder
from predicter import roc_curve, conf_matrix, grad_cam, ensemble_predict, base_predict

import keras

def get_class_fine_tuning_parameter_base() -> dict:
    """
    Get parameter sample for class fine_tuning (like Keras)
    Returns:
        dict: parameter sample generated by trial object
    """
    my_IDG_options={
        'rescale': 1.0/255.0
        , 'width_shift_range': 0.2
        , 'height_shift_range': 0.2
        , 'horizontal_flip': True
        , 'vertical_flip': True
        , 'shear_range': 20
        , 'zoom_range': 0.2
        , 'rotation_range': 20
        , 'channel_shift_range': 50
        , 'brightness_range': [0.3, 1.0]
        , 'random_erasing_prob': 0.5
        , 'random_erasing_maxpixel': 255
        , 'mix_up_alpha': 0.2 # mixup
        #, 'random_crop': [224,224] # random_crop size
    }

    train_augmentor_options = {
        'input_width': 100
        , 'input_height': 100
        , 'random_dist_prob': 0.3
        , 'zoom_prob': 0.3
        , 'zoom_min': 0.5
        , 'zoom_max': 1.9
        , 'flip_left_right': 0.3
        , 'flip_top_bottom': 0.3
        , 'random_erasing_prob': 0.3
        , 'random_erasing_area': 0.3
    }

    return {
        'output_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\results\InceptionResNetV2+attention_epoch10_from_02_keras_py',
        'gpu_count': 1,
        'img_rows': 100,
        'img_cols': 100,
        'channels': 3,
        'batch_size': 50,
        'classes': ['Cat', 'Dog'],
        'num_classes': 2,
        'train_data_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\images\small_set\train',
        'validation_data_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\images\small_set\validation',
        'test_data_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\images\small_set\validation',
        'color_mode': 'rgb',
        'class_mode': 'categorical', # generatorのラベルをone-hotベクトルに変換する場合。generatorのラベルを0か1のどちらかに変えるだけなら'binary'
        'activation': 'softmax',
        'loss': 'categorical_crossentropy',
        'metrics': ['accuracy'],
        'model_path': None,
        'num_epoch': 2,
        'n_multitask': 1, # マルチタスクのタスク数
        'multitask_pred_n_node': 1, # マルチタスクの各クラス数
        # model param
        'weights': 'imagenet',
        'choice_model': 'VGG16',
        'fcpool': 'GlobalAveragePooling2D',
        'is_skip_bn': True,
        'trainable': 15,
        'efficientnet_num': 7,
        # full layer param
        'fcs': [],
        'drop': 0.5,
        'is_add_batchnorm': True,
        'l2_rate': 1e-4,
        # optimizer param
        'choice_optim': 'sgd',
        'lr': 1e-1,
        'decay': 0.0,
        'my_IDG_options': my_IDG_options,
        'train_augmentor_options': train_augmentor_options,
        'TTA': 'flip',
        'TTA_rotate_deg': 0,
        'TTA_crop_num': 0,
        'TTA_crop_size': [224, 224],
        'preprocess': 1.0,
        'resize_size': [100, 100],
        'is_flow': False,
        'is_flow_from_directory': True,
        'is_flow_from_dataframe': False
    }

def train_directory(args, is_lr_finder=False):
    #### train validation data load ####
    d_cls = get_train_valid_test.LabeledDataset([args['img_rows'], args['img_cols'], args['channels']]
                                                , args['batch_size']
                                                , valid_batch_size=args['batch_size']
                                                , train_samples=len(util.find_img_files(args['train_data_dir']))
                                                , valid_samples=len(util.find_img_files(args['validation_data_dir']))
                                                )
    if args['is_flow']:
        # 指定ディレクトリの前処理済み画像、ラベル、ファイルパスロード
        d_cls.X_train, d_cls.y_train, train_paths = base_dataset.load_my_data(args['train_data_dir']
                                                                    , classes=args['classes']
                                                                    , img_height=args['img_rows'], img_width=args['img_cols'], channel=args['channels']
                                                                    , is_pytorch=False)
        d_cls.X_valid, d_cls.y_valid, valid_paths = base_dataset.load_my_data(args['validation_data_dir']
                                                                    , classes=args['classes']
                                                                    , img_height=args['img_rows'], img_width=args['img_cols'], channel=args['channels']
                                                                    , is_pytorch=False)
        d_cls.X_train, d_cls.X_valid = d_cls.X_train*255., d_cls.X_valid*255.
        d_cls.create_my_generator_flow(my_IDG_options=args['my_IDG_options'])

    elif args['is_flow_from_directory']:
        d_cls.create_my_generator_flow_from_directory(args['train_data_dir']
                                                        , args['classes']
                                                        , valid_data_dir=args['validation_data_dir']
                                                        , color_mode=args['color_mode']
                                                        , class_mode=args['class_mode']
                                                        , my_IDG_options=args['my_IDG_options'])
        #d_cls.train_gen_augmentor = d_cls.create_augmentor_util_from_directory(args['train_data_dir']
        #                                                                       , args['batch_size']
        #                                                                       , augmentor_options=args['train_augmentor_options'])

    # binaryラベルのgeneratorをマルチタスクgeneratorに変換するラッパー
    if args['n_multitask'] > 1 and args['multitask_pred_n_node'] == 1:
        d_cls.train_gen = get_train_valid_test.binary_generator_multi_output_wrapper(d_cls.train_gen)
        d_cls.valid_gen = get_train_valid_test.binary_generator_multi_output_wrapper(d_cls.valid_gen)

    #### model ####
    os.makedirs(args['output_dir'], exist_ok=True)
    model, orig_model = define_model.get_fine_tuning_model(args['output_dir']
                                                            , args['img_rows'], args['img_cols'], args['channels']
                                                            , args['num_classes']
                                                            , args['choice_model']
                                                            , trainable=args['trainable']
                                                            , fcpool=args['fcpool']
                                                            , activation=args['activation'], weights=args['weights'])
    optim = define_model.get_optimizers(choice_optim=args['choice_optim'], lr=args['lr'], decay=args['decay'])
    model.compile(loss=args['loss'], optimizer=optim, metrics=args['metrics'])

    cb = my_callback.get_base_cb(args['output_dir'], args['num_epoch'], early_stopping=args['num_epoch']//3)

    # lr_finder
    if is_lr_finder:
        lr_finder.run(model, d_cls.train_gen, args['batch_size'], d_cls.init_train_steps_per_epoch, output_dir=args['output_dir'])

    #### train ####
    start_time = time.time()
    hist = model.fit_generator(
        d_cls.train_gen,
        steps_per_epoch = d_cls.init_train_steps_per_epoch,
        epochs = args['num_epoch'],
        validation_data = d_cls.valid_gen,
        validation_steps = d_cls.init_valid_steps_per_epoch,
        verbose = 2,# 1:ログをプログレスバーで標準出力 2:最低限の情報のみ出す
        callbacks = cb
        )
    end_time = time.time()
    print("Elapsed Time : {:.2f}sec".format(end_time - start_time))

    plot_log.plot_results(args['output_dir'], os.path.join(args['output_dir'], 'tsv_logger.tsv'))

    return hist

def pred_directory(args):
    #### test data load ####
    d_cls = get_train_valid_test.LabeledDataset([args['img_rows'], args['img_cols'], args['channels']]
                                                , args['batch_size']
                                                , valid_batch_size=args['batch_size'])
    if args['is_flow']:
        # 指定ディレクトリの前処理済み画像、ラベル、ファイルパスロード
        d_cls.X_test, d_cls.y_test, test_paths = base_dataset.load_my_data(args['test_data_dir']
                                                                            , classes=args['classes']
                                                                            , img_height=args['img_rows'], img_width=args['img_cols'], channel=args['channels']
                                                                            , is_pytorch=False)
        d_cls.create_test_generator()

    elif args['is_flow_from_directory']:
        d_cls.create_my_generator_flow_from_directory(args['train_data_dir']
                                                        , args['classes']
                                                        , test_data_dir=args['test_data_dir']
                                                        , color_mode=args['color_mode']
                                                        , class_mode=args['class_mode']
                                                        , my_IDG_options={'rescale': 1/255.})

    # binaryラベルのgeneratorをマルチタスクgeneratorに変換するラッパー
    if args['n_multitask'] > 1 and args['multitask_pred_n_node'] == 1:
        d_cls.test_gen = get_train_valid_test.binary_generator_multi_output_wrapper(d_cls.test_gen)

    # generator predict TTA
    load_model = keras.models.load_model(os.path.join(args['output_dir'], 'best_val_loss.h5'))
    pred_tta = base_predict.predict_tta_generator(load_model
                                                    , d_cls.test_gen
                                                    , TTA=args['TTA']
                                                    , TTA_rotate_deg=args['TTA_rotate_deg']
                                                    , TTA_crop_num=args['TTA_crop_num'], TTA_crop_size=args['TTA_crop_size']
                                                    , resize_size=[args['img_rows'], args['img_cols']])
    pred_tta_df = base_predict.get_predict_generator_results(pred_tta, d_cls.test_gen, classes_list=args['classes'])
    # 混同行列作成
    base_predict.conf_matrix_from_pred_classes_generator(pred_tta_df, args['classes'], args['output_dir'])

class OptunaCallback(keras.callbacks.Callback):
    """
    Optunaでの枝刈り（最終的な結果がどのぐらいうまくいきそうかを大まかに予測し、良い結果を残すことが見込まれない試行は、最後まで行うことなく早期終了）
    https://qiita.com/koshian2/items/107c386f81c9bb7f8df3
    """
    def __init__(self, trial, prune):
        self.trial = trial
        self.prune = prune

    def on_epoch_end(self, epoch, logs):
        current_val_error = logs["val_loss"]# 1.0 - logs["val_acc"]
        # epochごとの値記録（intermediate_values）
        self.trial.report(current_val_error, step=epoch)
        if self.prune == True:
            # 打ち切り判定
            if self.trial.should_prune(epoch):
                # MedianPrunerのデフォルトの設定で、最初の5trialをたたき台して使って、以降のtrialで打ち切っていく
                raise optuna.structs.TrialPruned()

class Objective(object):

    def get_class_fine_tuning_parameter_suggestions(self, trial) -> dict:
        """
        Get parameter sample for class fine_tuning (like Keras)
        Args:
            trial(trial.Trial):
        Returns:
            dict: parameter sample generated by trial object
        """

        my_IDG_options = {
            'rescale': 1.0/255.0,
            'width_shift_range': trial.suggest_categorical('height_shift_range', [0.0, 0.25]),
            'height_shift_range': trial.suggest_categorical('height_shift_range', [0.0, 0.25]),
            'horizontal_flip': trial.suggest_categorical('horizontal_flip', [True, False]),
            'vertical_flip': trial.suggest_categorical('vertical_flip', [True, False]),
            'shear_range': trial.suggest_categorical('shear_range', [0.0, 20, 50]),
            'zoom_range': trial.suggest_categorical('zoom_range', [0.0, 0.2, 0.5]),
            'rotation_range': trial.suggest_categorical('rotation_range', [0.0, 45, 60, 90]),
            'channel_shift_range': trial.suggest_categorical('channel_shift_range', [0.0, 100, 200]),
            'brightness_range': trial.suggest_categorical('brightness_range', [[1.0, 1.0], [0.3, 1.0]]),
            # MyImageDataGenerator param
            'random_erasing_prob': trial.suggest_categorical('random_erasing_prob', [0.0, 0.5]),
            'random_erasing_maxpixel': 255.,
            'mix_up_alpha': trial.suggest_categorical('mix_up_alpha', [0.0, 0.2]),
            'ricap_beta': trial.suggest_categorical('ricap_beta', [0.0, 0.3]),
            'is_base_aug': trial.suggest_categorical('is_base_aug', [False]),
            'is_grayscale': trial.suggest_categorical('is_grayscale', [False]),
        }

        train_augmentor_options = {
            'rescale': 1.0/255.0,
            'rotate90': trial.suggest_categorical('rotate90', [0.0, 0.5]),
            'rotate180': trial.suggest_categorical('rotate180', [0.0, 0.5]),
            'rotate270': trial.suggest_categorical('rotate270', [0.0, 0.5]),
            'rotate_prob': trial.suggest_categorical('rotate_prob', [0.0, 0.5]),
            'rotate_max_left': trial.suggest_categorical('rotate_max_left', [20, 60, 90]),
            'rotate_max_right': trial.suggest_categorical('rotate_max_right', [20, 60, 90]),
            'crop_prob': trial.suggest_categorical('crop_prob', [0.0, 0.5]),
            'crop_area': trial.suggest_categorical('crop_area', [0.8, 0.5]),
            'crop_by_size_prob': trial.suggest_categorical('crop_by_size_prob', [0.0, 0.5]),
            'crop_by_width': trial.suggest_categorical('crop_by_width', [224]),
            'crop_by_height': trial.suggest_categorical('crop_by_height', [224]),
            'crop_by_centre': trial.suggest_categorical('crop_by_centre', [True, False]),
            'shear_prob': trial.suggest_categorical('shear_prob', [0.0, 0.5]),
            'shear_magni': trial.suggest_categorical('shear_magni', [20, 50]),
            'skew_prob': trial.suggest_categorical('skew_prob', [0.0, 0.5]),
            'skew_magni': trial.suggest_categorical('skew_magni', [20, 50]),
            'zoom_prob': trial.suggest_categorical('zoom_prob', [0.0, 0.5]),
            'zoom_min': trial.suggest_categorical('zoom_min', [0.2, 0.5, 0.9]),
            'zoom_max': trial.suggest_categorical('zoom_max', [1.2, 1.5, 1.9]),
            'flip_left_right': trial.suggest_categorical('flip_left_right', [0.0, 0.5]),
            'flip_top_bottom': trial.suggest_categorical('flip_top_bottom', [0.0, 0.5]),
            'random_erasing_prob': trial.suggest_categorical('random_erasing_prob', [0.0, 0.5]),
            'random_erasing_area': trial.suggest_categorical('random_erasing_area', [0.3]),
            'random_dist_prob': trial.suggest_categorical('random_dist_prob', [0.0, 0.5]),
            'random_dist_grid_width': trial.suggest_categorical('random_dist_grid_width', [4]),
            'random_dist_grid_height': trial.suggest_categorical('random_dist_grid_height', [4]),
            'random_dist_grid_height': trial.suggest_categorical('random_dist_grid_height', [4]),
            'random_dist_magnitude': trial.suggest_categorical('random_dist_magnitude', [8]),
            'black_and_white': trial.suggest_categorical('black_and_white', [0.0, 0.5]),
            'greyscale': trial.suggest_categorical('greyscale', [0.0, 0.5]),
            'invert': trial.suggest_categorical('invert', [0.0, 0.5])
        }

        return {
            'output_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\results\VGG16',
            'gpu_count': 1,
            'img_rows': 100,
            'img_cols': 100,
            'channels': 3,
            'batch_size': 50,
            'classes': ['Cat', 'Dog'],
            'num_classes': 2,
            'train_data_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\images\small_set\train',
            'validation_data_dir': r'D:\work\kaggle_data\Cats_VS._Dogs\images\small_set\validation',
            'color_mode': 'rgb',
            'class_mode': 'categorical', # generatorのラベルをone-hotベクトルに変換する場合。generatorのラベルを0か1のどちらかに変えるだけなら'binary'
            'activation': 'softmax',
            'loss': 'categorical_crossentropy',
            'metrics': ['accuracy'],
            'model_path': None,
            'num_epoch': 2,
            'n_multitask': 1, # マルチタスクのタスク数
            'multitask_pred_n_node': 1, # マルチタスクの各クラス数
            # model param
            'weights': 'imagenet',
            'choice_model': trial.suggest_categorical('choice_model', ['VGG16']),#'choice_model': trial.suggest_categorical('choice_model', ['InceptionV3', 'EfficientNet']),
            'fcpool': trial.suggest_categorical('fcpool', ['attention', 'GlobalAveragePooling2D']),
            'is_skip_bn': trial.suggest_categorical('is_skip_bn', [True, False]),
            'trainable': trial.suggest_categorical('trainable', ['all', 100, 200, 300, 400, 500, 600]),
            'efficientnet_num': trial.suggest_categorical('efficientnet_num', [3,4,5,6,7]),
            # full layer param
            'fcs': trial.suggest_categorical('fcs', [[], [100], [256], [512, 256], [1024, 512, 256]]),
            'drop': trial.suggest_categorical('drop', [0.3, 0.5, 0.7]),
            'is_add_batchnorm': trial.suggest_categorical('is_add_batchnorm', [True, False]),
            'l2_rate': trial.suggest_categorical('l2_rate', [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]),
            # optimizer param
            'choice_optim': trial.suggest_categorical('choice_optim', ['sgd', 'adadelta', 'adam', 'adamax', 'nadam', 'adabound']),
            'lr': trial.suggest_categorical('lr', [1e-3, 1e-2, 1e-1]),
            'decay': trial.suggest_categorical('decay', [0.0, 1e-6, 1e-5, 1e-4]), # 各更新上の学習率減衰
            # data augment
            'my_IDG_options': my_IDG_options,
            'train_augmentor_options': train_augmentor_options,
            'TTA': 'flip',
            'TTA_rotate_deg': 0,
            'TTA_crop_num': 0,
            'TTA_crop_size': [224, 224],
            'preprocess': 1.0,
            'resize_size': [100, 100],
            'is_flow': False,
            'is_flow_from_directory': True,
            'is_flow_from_dataframe': False
        }

    def trial_train_directory(self, trial, args):
        keras.backend.clear_session()
        #### train validation data load ####
        d_cls = get_train_valid_test.LabeledDataset([args['img_rows'], args['img_cols'], args['channels']]
                                                    , args['batch_size']
                                                    , valid_batch_size=args['batch_size']
                                                    , train_samples=len(util.find_img_files(args['train_data_dir']))
                                                    , valid_samples=len(util.find_img_files(args['validation_data_dir']))
                                                    )
        if args['is_flow']:
            # 指定ディレクトリの前処理済み画像、ラベル、ファイルパスロード
            d_cls.X_train, d_cls.y_train, train_paths = base_dataset.load_my_data(args['train_data_dir']
                                                                        , classes=args['classes']
                                                                        , img_height=args['img_rows'], img_width=args['img_cols'], channel=args['channels']
                                                                        , is_pytorch=False)
            d_cls.X_valid, d_cls.y_valid, valid_paths = base_dataset.load_my_data(args['validation_data_dir']
                                                                        , classes=args['classes']
                                                                        , img_height=args['img_rows'], img_width=args['img_cols'], channel=args['channels']
                                                                        , is_pytorch=False)
            d_cls.X_train, d_cls.X_valid = d_cls.X_train*255., d_cls.X_valid*255.
            d_cls.create_my_generator_flow(my_IDG_options=args['my_IDG_options'])

        elif args['is_flow_from_directory']:
            d_cls.create_my_generator_flow_from_directory(args['train_data_dir']
                                                            , args['classes']
                                                            , valid_data_dir=args['validation_data_dir']
                                                            , color_mode=args['color_mode']
                                                            , class_mode=args['class_mode']
                                                            , my_IDG_options=args['my_IDG_options'])
            #d_cls.train_gen_augmentor = d_cls.create_augmentor_util_from_directory(args['train_data_dir']
            #                                                                       , args['batch_size']
            #                                                                       , augmentor_options=args['train_augmentor_options'])

        # binaryラベルのgeneratorをマルチタスクgeneratorに変換するラッパー
        if args['n_multitask'] > 1 and args['multitask_pred_n_node'] == 1:
            d_cls.train_gen = get_train_valid_test.binary_generator_multi_output_wrapper(d_cls.train_gen)
            d_cls.valid_gen = get_train_valid_test.binary_generator_multi_output_wrapper(d_cls.valid_gen)

        #### model ####
        os.makedirs(args['output_dir'], exist_ok=True)
        model, orig_model = define_model.get_fine_tuning_model(args['output_dir']
                                                                , args['img_rows'], args['img_cols'], args['channels']
                                                                , args['num_classes']
                                                                , args['choice_model']
                                                                , trainable=args['trainable']
                                                                , fcpool=args['fcpool']
                                                                , activation=args['activation'], weights=args['weights'])
        optim = define_model.get_optimizers(choice_optim=args['choice_optim'], lr=args['lr'], decay=args['decay'])
        model.compile(loss=args['loss'], optimizer=optim, metrics=args['metrics'])

        cb = my_callback.get_base_cb(args['output_dir'], args['num_epoch'], early_stopping=args['num_epoch']//3)
        cb.append(OptunaCallback(trial, True))

        #### train ####
        hist = model.fit_generator(
            d_cls.train_gen,
            steps_per_epoch = d_cls.init_train_steps_per_epoch,
            epochs = args['num_epoch'],
            validation_data = d_cls.valid_gen,
            validation_steps = d_cls.init_valid_steps_per_epoch,
            verbose = 2,# 1:ログをプログレスバーで標準出力 2:最低限の情報のみ出す
            callbacks = cb
            )

        return hist

    def __call__(self, trial):
        args = self.get_class_fine_tuning_parameter_suggestions(trial)
        print(args)

        trial_best_loss = 1000.0
        #trial_best_err = 1000.0

        hist = self.trial_train_directory(trial, args)

        check_loss = np.min(hist.history['val_loss']) # check_dataは小さい方が精度良いようにしておく
        if check_loss < trial_best_loss:
            print('check_loss, trial_best_loss:', str(check_loss), str(trial_best_loss))
            trial_best_loss = check_loss
            if os.path.exists(os.path.join(args['output_dir'], 'ModelCheckpoint_val_loss.h5')) == True:
                shutil.copyfile(os.path.join(args['output_dir'], 'ModelCheckpoint_val_loss.h5'), os.path.join(args['output_dir'], 'best_trial_loss.h5'))

        #check_err = 1.0 - np.max(hist.history['val_acc']) # check_dataは小さい方が精度良いようにしておく
        #if check_err < trial_best_err:
        #    print('check_err, trial_best_err:', str(check_err), str(trial_best_err))
        #    trial_best_err = check_err
        #    if os.path.exists(os.path.join(args['output_dir'], 'ModelCheckpoint_val_acc.h5')) == True:
        #        shutil.copyfile(os.path.join(args['output_dir'], 'ModelCheckpoint_val_acc.h5'), os.path.join(args['output_dir'], 'best_trial_acc.h5'))

        # acc とloss の記録
        trial.set_user_attr('loss', np.min(hist.history['loss']))
        trial.set_user_attr('val_loss', np.min(hist.history['val_loss']))

        try: # optuna v0.18以上だとtryで囲まないとエラーでtrial落ちる
            return np.min(hist.history['val_loss'])
        except Exception as e:
            traceback.print_exc() # Exceptionが発生した際に表示される全スタックトレース表示
            return e # 例外を返さないとstudy.csvにエラー内容が記載されない

if __name__ == '__main__':
    import matplotlib
    matplotlib.use('Agg')

    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', choices=['train', 'predict', 'tuning'])
    parser.add_argument('--grad_cam_model_path', type=str, default=None)
    parser.add_argument('--grad_cam_image_dir', type=str, default=None)
    parser.add_argument('--study_name', help="Optuna trials study name", type=str, default='study')
    parser.add_argument('--n_trials', help="Optuna trials number", type=int, default=2)
    parser.add_argument('--tuning_output_dir', help="Optuna trials output_dir", type=str, default=r'D:\work\kaggle_data\Cats_VS._Dogs\results\VGG16')
    p_args = parser.parse_args()

    if p_args.mode == 'train':
        args = get_class_fine_tuning_parameter_base()
        train_directory(args)

    if p_args.mode == 'predict':
        args = get_class_fine_tuning_parameter_base()
        pred_directory(args)

    if p_args.grad_cam_model_path is not None and p_args.grad_cam_image_dir is not None:
        args = get_class_fine_tuning_parameter_base()
        for i,p in tqdm(enumerate(util.find_img_files(p_args.grad_cam_image_dir))):
            # 50枚ごとにモデル再ロード
            if i % 50 == 0:
                keras.backend.clear_session()
                keras.backend.set_learning_phase(0)
                model = keras.models.load_model(p_args.grad_cam_model_path, compile=False)
            # p_args.grad_cam_image_dirと同じディレクトリにGradCAM画像出力
            grad_cam.image2gradcam(model, p, is_gradcam_plus=False)

    if p_args.mode == 'tuning':
        study = optuna.create_study(direction='minimize', study_name=p_args.study_name, storage=f"sqlite:///{p_args.tuning_output_dir}/{p_args.study_name}.db", load_if_exists=True)
        study.optimize(Objective(), n_trials=p_args.n_trials)
        study.trials_dataframe().to_csv(f"{p_args.tuning_output_dir}/{p_args.study_name}_history.csv", index=False)
        print(f"\nstudy.best_params:\n{study.best_params}")
        print(f"\nstudy.best_trial:\n{study.best_trial}")
