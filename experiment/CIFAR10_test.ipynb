{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/shingo/jupyter_notebook/tfgpu_py36_work/02_keras_py/experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shingo\\\\Anaconda3\\\\envs\\\\tfgpu113\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10の画像で多クラス分類モデル試す\n",
    "## <font color=\"Red\">画像（x）,ラベル（y）データそのまま取得できる場合で分類モデル作成<font>\n",
    "\n",
    "#### 自宅PC:tfgpu_py36_v3環境\n",
    "- C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\experiment \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールimport\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py')\n",
    "from dataset import plot_log, prepare_data, util#, gradcam_xlsx_onesheet_label_prob, orgimg_xlsx_onesheet\n",
    "from transformer import get_train_valid_test, my_generator\n",
    "from model import define_model, multi_loss, my_callback, my_metric\n",
    "from predicter import roc_curve, conf_matrix, grad_cam, ensemble_predict, base_predict\n",
    "from tuning import optuna_train_base, optuna_train_Tox21, optuna_util\n",
    "\n",
    "import pathlib\n",
    "#current_dir = pathlib.Path(\"__file__\").resolve().parent\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\Git\\keras-squeeze-excite-network')\n",
    "import se_inception_v3, se_densenet, se_inception_resnet_v2, se_resnet, se_resnext, se\n",
    "\n",
    "sys.path.append(r'C:\\Users\\shingo\\Git\\mixup-generator')\n",
    "from mixup_generator import MixupGenerator\n",
    "from random_eraser import get_random_eraser\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像をtrain/test set に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - ETA: 56:3 - ETA: 37:4 - ETA: 18:5 - ETA: 10:4 - ETA: 8:0 - ETA: 5: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 56 - ETA: 51 - ETA: 50 - ETA: 49 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 42 - ETA: 41 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 37 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 30s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "[3] label -> ex: 3 \n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(y_train.shape[0], 'train samples')\n",
    "print(y_test.shape[0], 'test samples')\n",
    "print(y_test[0], 'label -> ex: 3 ')\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print(y_test[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os, sys, glob, time\n",
    "\n",
    "# 出力ディレクトリ\n",
    "output_dir = r'D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_from_02_keras_py'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 入力層のサイズ\n",
    "#img_rows, img_cols, channels=331, 331, 3\n",
    "img_rows, img_cols, channels=32, 32, 3\n",
    "\n",
    "# 分類クラス\n",
    "class_name = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "classes = class_name\n",
    "nb_classes = len(classes)\n",
    "activation='softmax'\n",
    "\n",
    "# GradCamで切り出す層名\n",
    "layer_name = 'block5_conv3'#'block4_conv3'\n",
    "\n",
    "# ハイパーパラメータ\n",
    "num_epoch=5#2#10\n",
    "batch_size=100\n",
    "val_batch_size=100\n",
    "\n",
    "# optimizer のパラメータ\n",
    "choice_optim='sgd'\n",
    "lr=0.01#0.1 * batch_size / 128\n",
    "#decay=1e-3\n",
    "momentum=0.9\n",
    "\n",
    "# fine-tuningモデル\n",
    "choice_model='OctConv_WideResNet'#'VGG16'\n",
    "trainable=15\n",
    "\n",
    "# 全結合層\n",
    "FCnum=1\n",
    "\n",
    "# 学習打ち切りオプション\n",
    "early_stopping=10\n",
    "\n",
    "plateau_pati=5\n",
    "plateau_factor=0.5 # コールバックが起動したら学習率0.9倍\n",
    "plateau_monitor='val_loss'\n",
    "\n",
    "# https://qiita.com/ak11/items/67118e11b756b0ee83a5\n",
    "base_lr = lr #0.1 * batch_size / 128  # adamとかなら1e-3くらい。SGDなら例えば 0.1 * batch_size / 128 とかくらい。nadamなら0.002*10 ?\n",
    "lr_decay_rate = 1/2#1 / 3\n",
    "lr_steps = 2#4\n",
    "\n",
    "### 訓練画像水増しオプション\n",
    "# ImageDataGenerator\n",
    "rescale=1.0/255.0\n",
    "vertical_flip=True\n",
    "zoom_range=0.2\n",
    "rotation_range=20\n",
    "channel_shift_range=5.\n",
    "brightness_range=[0.3, 1.0]\n",
    "# custom param\n",
    "#mix_up_alpha=0.2# mixup alpha\n",
    "#random_crop=[224,224]# random_crop size\n",
    "random_erasing_prob = 0.5 # random_erasing 確率\n",
    "random_erasing_maxpixel = 255\n",
    "\n",
    "# MyImageDataGenerator のオプションを辞書型で詰める\n",
    "my_IDG_options={'rescale': rescale\n",
    "             , 'vertical_flip': vertical_flip\n",
    "             , 'zoom_range': zoom_range\n",
    "             , 'rotation_range': rotation_range \n",
    "             , 'channel_shift_range': channel_shift_range\n",
    "             , 'brightness_range': brightness_range\n",
    "             , 'random_erasing_prob': random_erasing_prob\n",
    "             , 'random_erasing_maxpixel': random_erasing_maxpixel\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generator定義\n",
    "- データ管理クラス：d_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- train_ImageDataGenerator -----\n",
      "use_mixup: False\n",
      "IDG_options: {'horizontal_flip': True, 'vertical_flip': True, 'rotation_range': 60, 'zoom_range': [0.5, 1.9], 'shear_range': 0.2, 'preprocessing_function': <function get_random_eraser.<locals>.eraser at 0x000001D356C36D08>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator at 0x1d3455600f0>,\n",
       " <keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator at 0x1d34547c9e8>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls = get_train_valid_test.LabeledDataset([img_rows, img_cols, channels]\n",
    "                                            , batch_size\n",
    "                                            , valid_batch_size=val_batch_size\n",
    "                                            )\n",
    "d_cls.X_train = x_train/255.0\n",
    "d_cls.y_train = y_train\n",
    "d_cls.X_valid = x_test/255.0\n",
    "d_cls.y_valid = y_test\n",
    "\n",
    "d_cls.split_train_valid()\n",
    "\n",
    "# ImageDataGenerator のオプションを辞書型で詰める\n",
    "# get_random_eraserでd_clsの値使うのでここで宣言しないとエラーになる\n",
    "horizontal_flip=True\n",
    "vertical_flip=True\n",
    "rotation_range=60\n",
    "zoom_range=[0.5, 1.9]\n",
    "shear_range=0.2\n",
    "IDG_options={'horizontal_flip': horizontal_flip\n",
    "             , 'vertical_flip': vertical_flip\n",
    "             , 'rotation_range': rotation_range\n",
    "             , 'zoom_range': zoom_range\n",
    "             , 'shear_range': shear_range\n",
    "             , 'preprocessing_function': get_random_eraser(v_l=np.min(d_cls.X_train), v_h=np.max(d_cls.X_train))\n",
    "            }\n",
    "\n",
    "d_cls.create_generator(IDG_options=IDG_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40670, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.cur_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.cur_X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(d_cls.y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.valid_gen.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(d_cls.valid_gen.y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cls.train_steps_per_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_flow_index',\n",
       " '_get_batches_of_transformed_samples',\n",
       " '_set_index_array',\n",
       " 'batch_index',\n",
       " 'batch_size',\n",
       " 'data_format',\n",
       " 'dtype',\n",
       " 'image_data_generator',\n",
       " 'index_array',\n",
       " 'index_generator',\n",
       " 'lock',\n",
       " 'n',\n",
       " 'next',\n",
       " 'on_epoch_end',\n",
       " 'reset',\n",
       " 'sample_weight',\n",
       " 'save_format',\n",
       " 'save_prefix',\n",
       " 'save_to_dir',\n",
       " 'seed',\n",
       " 'shuffle',\n",
       " 'total_batches_seen',\n",
       " 'white_list_formats',\n",
       " 'x',\n",
       " 'x_misc',\n",
       " 'y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(d_cls.valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(d_cls.valid_gen, 'filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3)\n",
      "(100, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "x,y = next(d_cls.train_gen)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[0])\n",
    "print(classes)\n",
    "plt.imshow(x[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワーク定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGG16+FC1+SE\n",
    "- 15層以前をfreeze(ただし、Batch Normalizationはfreeze解除)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- model_param -----\n",
      "output_dir = D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_from_02_keras_py\n",
      "img_rows img_cols channels = 32 32 3\n",
      "num_classes = 10\n",
      "choice_model trainable = OctConv_WideResNet 15\n",
      "fcs = [256]\n",
      "fcpool = GlobalAveragePooling2D\n",
      "pred_kernel_initializer pred_l2_rate = zeros 0.0001\n",
      "activation = softmax\n",
      "gpu_count = 1\n",
      "skip_bn = True\n",
      "n_multitask = 1\n",
      "oct_conv_alpha, wrn_N, wrn_k = 0.25 4 10\n",
      "WARNING:tensorflow:From C:\\Users\\shingo\\Anaconda3\\envs\\tfgpu113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "----- FC_layers -----\n",
      "WARNING:tensorflow:From C:\\Users\\shingo\\Anaconda3\\envs\\tfgpu113\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "dence dropout is_add_batchnorm kernel_initializer l2_rate = 256 0.5 None he_normal 0.0001\n",
      "---- choice_optim = sgd ----\n",
      "sgd_lr sgd_momentum sgd_decay sgd_nesterov = 0.01 0.9 0.0 True\n",
      "0 input_1\n",
      "1 average_pooling2d_1\n",
      "2 oct_conv2d_1\n",
      "3 batch_normalization_1\n",
      "4 batch_normalization_2\n",
      "5 activation_1\n",
      "6 activation_2\n",
      "7 oct_conv2d_2\n",
      "8 batch_normalization_5\n",
      "9 batch_normalization_6\n",
      "10 activation_5\n",
      "11 activation_6\n",
      "12 oct_conv2d_3\n",
      "13 conv2d_1\n",
      "14 conv2d_2\n",
      "15 batch_normalization_7\n",
      "16 batch_normalization_3\n",
      "17 batch_normalization_8\n",
      "18 batch_normalization_4\n",
      "19 activation_7\n",
      "20 activation_3\n",
      "21 activation_8\n",
      "22 activation_4\n",
      "23 add_1\n",
      "24 add_2\n",
      "25 oct_conv2d_4\n",
      "26 batch_normalization_9\n",
      "27 batch_normalization_10\n",
      "28 activation_9\n",
      "29 activation_10\n",
      "30 oct_conv2d_5\n",
      "31 batch_normalization_11\n",
      "32 batch_normalization_12\n",
      "33 activation_11\n",
      "34 activation_12\n",
      "35 add_3\n",
      "36 add_4\n",
      "37 oct_conv2d_6\n",
      "38 batch_normalization_13\n",
      "39 batch_normalization_14\n",
      "40 activation_13\n",
      "41 activation_14\n",
      "42 oct_conv2d_7\n",
      "43 batch_normalization_15\n",
      "44 batch_normalization_16\n",
      "45 activation_15\n",
      "46 activation_16\n",
      "47 add_5\n",
      "48 add_6\n",
      "49 oct_conv2d_8\n",
      "50 batch_normalization_17\n",
      "51 batch_normalization_18\n",
      "52 activation_17\n",
      "53 activation_18\n",
      "54 oct_conv2d_9\n",
      "55 batch_normalization_19\n",
      "56 batch_normalization_20\n",
      "57 activation_19\n",
      "58 activation_20\n",
      "59 add_7\n",
      "60 add_8\n",
      "61 average_pooling2d_2\n",
      "62 average_pooling2d_3\n",
      "63 oct_conv2d_10\n",
      "64 batch_normalization_23\n",
      "65 batch_normalization_24\n",
      "66 activation_23\n",
      "67 activation_24\n",
      "68 oct_conv2d_11\n",
      "69 conv2d_3\n",
      "70 conv2d_4\n",
      "71 batch_normalization_25\n",
      "72 batch_normalization_21\n",
      "73 batch_normalization_26\n",
      "74 batch_normalization_22\n",
      "75 activation_25\n",
      "76 activation_21\n",
      "77 activation_26\n",
      "78 activation_22\n",
      "79 add_9\n",
      "80 add_10\n",
      "81 oct_conv2d_12\n",
      "82 batch_normalization_27\n",
      "83 batch_normalization_28\n",
      "84 activation_27\n",
      "85 activation_28\n",
      "86 oct_conv2d_13\n",
      "87 batch_normalization_29\n",
      "88 batch_normalization_30\n",
      "89 activation_29\n",
      "90 activation_30\n",
      "91 add_11\n",
      "92 add_12\n",
      "93 oct_conv2d_14\n",
      "94 batch_normalization_31\n",
      "95 batch_normalization_32\n",
      "96 activation_31\n",
      "97 activation_32\n",
      "98 oct_conv2d_15\n",
      "99 batch_normalization_33\n",
      "100 batch_normalization_34\n",
      "101 activation_33\n",
      "102 activation_34\n",
      "103 add_13\n",
      "104 add_14\n",
      "105 oct_conv2d_16\n",
      "106 batch_normalization_35\n",
      "107 batch_normalization_36\n",
      "108 activation_35\n",
      "109 activation_36\n",
      "110 oct_conv2d_17\n",
      "111 batch_normalization_37\n",
      "112 batch_normalization_38\n",
      "113 activation_37\n",
      "114 activation_38\n",
      "115 add_15\n",
      "116 add_16\n",
      "117 average_pooling2d_4\n",
      "118 average_pooling2d_5\n",
      "119 oct_conv2d_18\n",
      "120 batch_normalization_41\n",
      "121 batch_normalization_42\n",
      "122 activation_41\n",
      "123 activation_42\n",
      "124 oct_conv2d_19\n",
      "125 conv2d_5\n",
      "126 conv2d_6\n",
      "127 batch_normalization_43\n",
      "128 batch_normalization_39\n",
      "129 batch_normalization_44\n",
      "130 batch_normalization_40\n",
      "131 activation_43\n",
      "132 activation_39\n",
      "133 activation_44\n",
      "134 activation_40\n",
      "135 add_17\n",
      "136 add_18\n",
      "137 oct_conv2d_20\n",
      "138 batch_normalization_45\n",
      "139 batch_normalization_46\n",
      "140 activation_45\n",
      "141 activation_46\n",
      "142 oct_conv2d_21\n",
      "143 batch_normalization_47\n",
      "144 batch_normalization_48\n",
      "145 activation_47\n",
      "146 activation_48\n",
      "147 add_19\n",
      "148 add_20\n",
      "149 oct_conv2d_22\n",
      "150 batch_normalization_49\n",
      "151 batch_normalization_50\n",
      "152 activation_49\n",
      "153 activation_50\n",
      "154 oct_conv2d_23\n",
      "155 batch_normalization_51\n",
      "156 batch_normalization_52\n",
      "157 activation_51\n",
      "158 activation_52\n",
      "159 add_21\n",
      "160 add_22\n",
      "161 oct_conv2d_24\n",
      "162 batch_normalization_54\n",
      "163 batch_normalization_53\n",
      "164 activation_54\n",
      "165 activation_53\n",
      "166 conv2d_8\n",
      "167 conv2d_7\n",
      "168 lambda_1\n",
      "169 add_23\n",
      "170 batch_normalization_55\n",
      "171 activation_55\n",
      "172 FC_avg\n",
      "173 FC0_dence\n",
      "174 FC0_act\n",
      "175 FC0_dropout\n",
      "176 pred\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_1 (OctConv2D)        [(None, 32, 32, 12), 864         input_1[0][0]                    \n",
      "                                                                 average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 12)   48          oct_conv2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 4)    16          oct_conv2d_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 12)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_2 (OctConv2D)        [(None, 32, 32, 120) 23040       activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 120)  480         oct_conv2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 40)   160         oct_conv2d_2[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 120)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 40)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_3 (OctConv2D)        [(None, 32, 32, 120) 230400      activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 120)  1560        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 40)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_7 (BatchNor (None, 32, 32, 120)  480         oct_conv2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 120)  480         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 40)   160         oct_conv2d_3[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 40)   160         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 120)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 120)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 40)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 40)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 120)  0           activation_7[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 40)   0           activation_8[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_4 (OctConv2D)        [(None, 32, 32, 120) 230400      add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 120)  480         oct_conv2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_4[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 120)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 40)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_5 (OctConv2D)        [(None, 32, 32, 120) 230400      activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 120)  480         oct_conv2d_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_5[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 120)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 40)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 120)  0           activation_11[0][0]              \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 40)   0           activation_12[0][0]              \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_6 (OctConv2D)        [(None, 32, 32, 120) 230400      add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 120)  480         oct_conv2d_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_6[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 120)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 40)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_7 (OctConv2D)        [(None, 32, 32, 120) 230400      activation_13[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 120)  480         oct_conv2d_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_7[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 120)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 40)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 120)  0           activation_15[0][0]              \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 40)   0           activation_16[0][0]              \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_8 (OctConv2D)        [(None, 32, 32, 120) 230400      add_5[0][0]                      \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         oct_conv2d_8[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_8[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 40)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_9 (OctConv2D)        [(None, 32, 32, 120) 230400      activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 120)  480         oct_conv2d_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 40)   160         oct_conv2d_9[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 120)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 40)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 120)  0           activation_19[0][0]              \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 40)   0           activation_20[0][0]              \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 120)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 8, 8, 40)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_10 (OctConv2D)       [(None, 16, 16, 240) 460800      average_pooling2d_2[0][0]        \n",
      "                                                                 average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_10[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 240)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 80)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_11 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 240)  29040       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 80)     3280        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 240)  960         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_11[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 80)     320         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 240)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 240)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 80)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 80)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 240)  0           activation_25[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 80)     0           activation_26[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_12 (OctConv2D)       [(None, 16, 16, 240) 921600      add_9[0][0]                      \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_12[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 240)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 80)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_13 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_27[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_29 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_13[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 240)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 80)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 240)  0           activation_29[0][0]              \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 80)     0           activation_30[0][0]              \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_14 (OctConv2D)       [(None, 16, 16, 240) 921600      add_11[0][0]                     \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_14[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 240)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 80)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_15 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_31[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_15[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 240)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 80)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 240)  0           activation_33[0][0]              \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 80)     0           activation_34[0][0]              \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_16 (OctConv2D)       [(None, 16, 16, 240) 921600      add_13[0][0]                     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_16[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 240)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 80)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_17 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_35[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 240)  960         oct_conv2d_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 80)     320         oct_conv2d_17[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 240)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 80)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 240)  0           activation_37[0][0]              \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 80)     0           activation_38[0][0]              \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 240)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 4, 4, 80)     0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_18 (OctConv2D)       [(None, 8, 8, 480),  1843200     average_pooling2d_4[0][0]        \n",
      "                                                                 average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_18[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 480)    0           batch_normalization_41[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_19 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_41[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 480)    115680      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 160)    12960       average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 480)    1920        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_19[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 160)    640         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 480)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 480)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 160)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 480)    0           activation_43[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 4, 160)    0           activation_44[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_20 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_17[0][0]                     \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_20[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 480)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_21 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_45[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_21[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 480)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 480)    0           activation_47[0][0]              \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 4, 4, 160)    0           activation_48[0][0]              \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_22 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_19[0][0]                     \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_22[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 480)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 160)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_23 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_23[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 480)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_21 (Add)                    (None, 8, 8, 480)    0           activation_51[0][0]              \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 4, 4, 160)    0           activation_52[0][0]              \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oct_conv2d_24 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_21[0][0]                     \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 160)    640         oct_conv2d_24[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 480)    1920        oct_conv2d_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 4, 4, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 480)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 640)    922240      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 640)    2765440     activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 8, 640)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 640)    0           conv2d_7[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 640)    2560        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 640)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FC_avg (GlobalAveragePooling2D) (None, 640)          0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "FC0_dence (Dense)               (None, 256)          164096      FC_avg[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC0_act (Activation)            (None, 256)          0           FC0_dence[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC0_dropout (Dropout)           (None, 256)          0           FC0_act[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 10)           2570        FC0_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 36,567,754\n",
      "Trainable params: 36,291,498\n",
      "Non-trainable params: 276,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "model, orig_model = define_model.get_fine_tuning_model(output_dir, img_rows, img_cols, channels, nb_classes\n",
    "                                                       , choice_model, trainable\n",
    "                                                       , fcs=[256]\n",
    "                                                       , activation=activation\n",
    "                                                      )\n",
    "# compile the model\n",
    "optim = define_model.get_optimizers(choice_optim=choice_optim, lr=lr, momentum=momentum, nesterov=True)#, decay=decay)\n",
    "#lr_metric = my_metric.get_lr_metric(optim)\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "              , optimizer=optim\n",
    "              , metrics=['accuracy'])\n",
    "              #, metrics=['accuracy', lr_metric])\n",
    "\n",
    "# finetunning用にレイヤーの数と名前を表示\n",
    "count= 0\n",
    "for layer in model.layers:\n",
    "    print(count, layer.name)\n",
    "    count+=1\n",
    "keras.utils.plot_model(model, to_file=os.path.join(output_dir, 'VGG16_FC1.svg'), show_shapes=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb(output_dir, cosine_annealing_num_epoch=None):\n",
    "    cb = []\n",
    "\n",
    "    # 学習率をエポック増やすごとにコサインカーブで上げ下げする. epochsはコサインカーブのほぼ半周期になるエポック数\n",
    "    cb.append(my_callback.cosine_annealing(epochs=num_epoch))\n",
    "\n",
    "    # ログを保存するカスタムコールバック\n",
    "    cb.append(my_callback.tsv_logger(os.path.join(output_dir, 'tsv_logger.tsv')))\n",
    "    \n",
    "    # epochごとに学習曲線保存する自作callback\n",
    "    cb.append(my_callback.learning_curve_plot(os.path.join(output_dir, 'learning_curve.png')))\n",
    "    \n",
    "    # 各エポックでval_lossが最小となるモデル保存\n",
    "    cb.append(keras.callbacks.ModelCheckpoint(filepath=os.path.join(output_dir, 'finetuning.h5'), monitor='val_loss', save_best_only=True, verbose=1))\n",
    "\n",
    "    # 過学習の抑制 <early_stopping_pati>step続けてval_loss減らなかったら打ち切る\n",
    "    cb.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stopping, verbose=1))\n",
    "    \n",
    "    return cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shingo\\Anaconda3\\envs\\tfgpu113\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "history = model.fit_generator(\n",
    "    d_cls.train_gen,\n",
    "    steps_per_epoch = d_cls.train_steps_per_epoch(),# 1エポックあたりの学習(step)回数\n",
    "    epochs = num_epoch,# エポック数\n",
    "    validation_data = d_cls.valid_gen,# 検証ファイル生成\n",
    "    validation_steps = d_cls.valid_steps_per_epoch(),# 検証するファイル数\n",
    "    verbose = 2,# 1:ログをプログレスバーで標準出力 2:最低限の情報のみ出す\n",
    "    callbacks = get_cb(output_dir, cosine_annealing_num_epoch=None)\n",
    "    )\n",
    "end_time = time.time()\n",
    "print(\"Elapsed Time : {:.2f}sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "#Jupyterでインライン表示するための宣言\n",
    "%matplotlib inline\n",
    "plot_log.plot_results(output_dir, os.path.join(output_dir, 'tsv_logger.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid setのloss,acc評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functionを使ったmodelを別環境で使用するには、modelをロードする際に引数として、[custom_objects]を指定するがある\n",
    "# https://qiita.com/tkinjo1/items/51f9e2d0d9c4659bde8a\n",
    "#model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_batch_size, test_batch_size の枚数だけevaluate\n",
    "scoreSeg = model.evaluate_generator(d_cls.valid_gen, val_batch_size)\n",
    "print(\"val_loss = \",scoreSeg[0])\n",
    "print(\"val_acc = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_generator はflow_from_directory でラベルクラスが親ディレクトリである場合しか使えない評価関数（lossとaccを出す）\n",
    "# なので、基本train/validation setにしか使えない（test setは正解ラベルないケースが普通なので）\n",
    "\n",
    "# evaluate_generator はgenerator だけ引数に渡したら全件予測してくれるみたい\n",
    "# ただし、batch size ごとに予測するから総数/batch_size が割り切れる数になっていないと、あまりの分が2回predictされてしまう\n",
    "# 安全な方法はbatch_size=1 にしたgenerator で実行（複数一気にpredictしないから時間かかる）\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "scoreSeg = model.evaluate_generator(d_cls.valid_gen)\n",
    "print(\"val_loss = \",scoreSeg[0])\n",
    "print(\"val_acc = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict+混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functionを使ったmodelを別環境で使用するには、modelをロードする際に引数として、[custom_objects]を指定するがある\n",
    "# https://qiita.com/tkinjo1/items/51f9e2d0d9c4659bde8a\n",
    "#load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generatorで全件予測\n",
    "pred_df = base_predict.pred_classes_generator(load_model, d_cls.valid_gen, classes_list=class_name)\n",
    "pred_df.to_csv(os.path.join(output_dir, 'pred.tsv'), sep='\\t')\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 予測結果のデータフレームから混同行列作成\n",
    "base_predict.conf_matrix_from_pred_classes_generator(pred_df, classes, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1件ずつ予測+GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functionを使ったmodelを別環境で使用するには、modelをロードする際に引数として、[custom_objects]を指定するがある\n",
    "# https://qiita.com/tkinjo1/items/51f9e2d0d9c4659bde8a\n",
    "#load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# 画像のid\n",
    "id = 0\n",
    "\n",
    "# 前処理済み入力画像データ\n",
    "X = d_cls.X_valid[id]\n",
    "x = X*255.0\n",
    "print(x.shape)\n",
    "\n",
    "# grad_cam掛けるクラスid取得\n",
    "pred_id = base_predict.pred_from_1X(load_model, X, classes)\n",
    "print('pred_id:', str(pred_id))\n",
    "\n",
    "# 4次元テンソルへ変換\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# grad_cam\n",
    "class_output = load_model.output[:, pred_id]\n",
    "jetcam = grad_cam.grad_cam(load_model, X, x, layer_name, img_rows, img_cols, class_output)\n",
    "\n",
    "# Grad-cam画像保存+表示\n",
    "grad_cam_img = image.array_to_img(jetcam)\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()\n",
    "\n",
    "# TP/FN/FP/TN/NAN を判定し、判定結果を出力パスに含める\n",
    "y_true_label = d_cls.y_valid[id].argmax() # 正解ラベルであるファイルの直上のフォルダ名のみを取得\n",
    "print('y_true_label :', y_true_label)\n",
    "judge = grad_cam.judge_evaluate(pred_id, y_true_label, positive=y_true_label, negative=pred_id)\n",
    "judge_out_grad_cam_dir = os.path.join(output_dir, 'gradcam', judge)\n",
    "out_jpg = os.path.join(judge_out_grad_cam_dir, str(y_true_label)+'_pred_'+classes[pred_id]+'.jpg')\n",
    "print(out_jpg)\n",
    "\n",
    "# ファイル出力\n",
    "#os.makedirs(judge_out_grad_cam_dir, exist_ok=True)\n",
    "#grad_cam_img.save(out_jpg, 'JPEG', quality=100, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K.set_learning_phase 指定無しのGradCamとK.set_learning_phase(0) のGradCamは同じ結果になる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "#load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))\n",
    "\n",
    "# 画像のid\n",
    "id = 0\n",
    "\n",
    "# 前処理済み入力画像データ\n",
    "X = d_cls.X_valid[id]\n",
    "x = X*255.0\n",
    "print(x.shape)\n",
    "\n",
    "# grad_cam掛けるクラスid取得\n",
    "pred_id = base_predict.pred_from_1X(load_model, X, classes)\n",
    "print('pred_id:', str(pred_id))\n",
    "\n",
    "# 4次元テンソルへ変換\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# grad_cam\n",
    "class_output = load_model.output[:, pred_id]\n",
    "jetcam = grad_cam.grad_cam(load_model, X, x, layer_name, img_rows, img_cols, class_output)\n",
    "\n",
    "# Grad-cam画像保存+表示\n",
    "grad_cam_img = image.array_to_img(jetcam)\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()\n",
    "\n",
    "# TP/FN/FP/TN/NAN を判定し、判定結果を出力パスに含める\n",
    "y_true_label = d_cls.y_valid[id].argmax() # 正解ラベルであるファイルの直上のフォルダ名のみを取得\n",
    "print('y_true_label :', y_true_label)\n",
    "judge = grad_cam.judge_evaluate(pred_id, y_true_label, positive=y_true_label, negative=pred_id)\n",
    "judge_out_grad_cam_dir = os.path.join(output_dir, 'gradcam', judge)\n",
    "out_jpg = os.path.join(judge_out_grad_cam_dir, str(y_true_label)+'_pred_'+classes[pred_id]+'.jpg')\n",
    "print(out_jpg)\n",
    "\n",
    "# ファイル出力\n",
    "#os.makedirs(judge_out_grad_cam_dir, exist_ok=True)\n",
    "#grad_cam_img.save(out_jpg, 'JPEG', quality=100, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K.set_learning_phase(1) はやっぱ間違い \n",
    "### K.set_learning_phase 指定無しのGradCamと違う結果になる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "#load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))\n",
    "\n",
    "# 画像のid\n",
    "id = 0\n",
    "\n",
    "# 前処理済み入力画像データ\n",
    "X = d_cls.X_valid[id]\n",
    "x = X*255.0\n",
    "print(x.shape)\n",
    "\n",
    "# grad_cam掛けるクラスid取得\n",
    "pred_id = base_predict.pred_from_1X(load_model, X, classes)\n",
    "print('pred_id:', str(pred_id))\n",
    "\n",
    "# 4次元テンソルへ変換\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# grad_cam\n",
    "class_output = load_model.output[:, pred_id]\n",
    "jetcam = grad_cam.grad_cam(load_model, X, x, layer_name, img_rows, img_cols, class_output)\n",
    "\n",
    "# Grad-cam画像保存+表示\n",
    "grad_cam_img = image.array_to_img(jetcam)\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()\n",
    "\n",
    "# TP/FN/FP/TN/NAN を判定し、判定結果を出力パスに含める\n",
    "y_true_label = d_cls.y_valid[id].argmax() # 正解ラベルであるファイルの直上のフォルダ名のみを取得\n",
    "print('y_true_label :', y_true_label)\n",
    "judge = grad_cam.judge_evaluate(pred_id, y_true_label, positive=y_true_label, negative=pred_id)\n",
    "judge_out_grad_cam_dir = os.path.join(output_dir, 'gradcam', judge)\n",
    "out_jpg = os.path.join(judge_out_grad_cam_dir, str(y_true_label)+'_pred_'+classes[pred_id]+'.jpg')\n",
    "print(out_jpg)\n",
    "\n",
    "# ファイル出力\n",
    "#os.makedirs(judge_out_grad_cam_dir, exist_ok=True)\n",
    "#grad_cam_img.save(out_jpg, 'JPEG', quality=100, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 他の画像でもGradCam実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "load_model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# 画像のid\n",
    "id = 6\n",
    "\n",
    "# 前処理済み入力画像データ\n",
    "X = d_cls.X_valid[id]\n",
    "x = X*255.0\n",
    "print(x.shape)\n",
    "\n",
    "# grad_cam掛けるクラスid取得\n",
    "pred_id = base_predict.pred_from_1X(load_model, X, classes)\n",
    "print('pred_id:', str(pred_id))\n",
    "\n",
    "# 4次元テンソルへ変換\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# grad_cam\n",
    "class_output = load_model.output[:, pred_id]\n",
    "jetcam = grad_cam.grad_cam(load_model, X, x, layer_name, img_rows, img_cols, class_output)\n",
    "\n",
    "# Grad-cam画像保存+表示\n",
    "grad_cam_img = image.array_to_img(jetcam)\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()\n",
    "\n",
    "# TP/FN/FP/TN/NAN を判定し、判定結果を出力パスに含める\n",
    "y_true_label = d_cls.y_valid[id].argmax() # 正解ラベルであるファイルの直上のフォルダ名のみを取得\n",
    "print('y_true_label :', y_true_label)\n",
    "judge = grad_cam.judge_evaluate(pred_id, y_true_label, positive=y_true_label, negative=pred_id)\n",
    "judge_out_grad_cam_dir = os.path.join(output_dir, 'gradcam', judge)\n",
    "out_jpg = os.path.join(judge_out_grad_cam_dir, str(y_true_label)+'_pred_'+classes[pred_id]+'.jpg')\n",
    "print(out_jpg)\n",
    "\n",
    "# ファイル出力\n",
    "#os.makedirs(judge_out_grad_cam_dir, exist_ok=True)\n",
    "#grad_cam_img.save(out_jpg, 'JPEG', quality=100, optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# 画像のid\n",
    "id = 18\n",
    "\n",
    "# 前処理済み入力画像データ\n",
    "X = d_cls.X_valid[id]\n",
    "x = X*255.0\n",
    "print(x.shape)\n",
    "\n",
    "# grad_cam掛けるクラスid取得\n",
    "pred_id = base_predict.pred_from_1X(load_model, X, classes)\n",
    "print('pred_id:', str(pred_id))\n",
    "\n",
    "# 4次元テンソルへ変換\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# grad_cam\n",
    "class_output = load_model.output[:, pred_id]\n",
    "jetcam = grad_cam.grad_cam(load_model, X, x, layer_name, img_rows, img_cols, class_output)\n",
    "\n",
    "# Grad-cam画像保存+表示\n",
    "grad_cam_img = image.array_to_img(jetcam)\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()\n",
    "\n",
    "# TP/FN/FP/TN/NAN を判定し、判定結果を出力パスに含める\n",
    "y_true_label = d_cls.y_valid[id].argmax() # 正解ラベルであるファイルの直上のフォルダ名のみを取得\n",
    "print('y_true_label :', y_true_label)\n",
    "judge = grad_cam.judge_evaluate(pred_id, y_true_label, positive=y_true_label, negative=pred_id)\n",
    "judge_out_grad_cam_dir = os.path.join(output_dir, 'gradcam', judge)\n",
    "out_jpg = os.path.join(judge_out_grad_cam_dir, str(y_true_label)+'_pred_'+classes[pred_id]+'.jpg')\n",
    "print(out_jpg)\n",
    "\n",
    "# ファイル出力\n",
    "#os.makedirs(judge_out_grad_cam_dir, exist_ok=True)\n",
    "#grad_cam_img.save(out_jpg, 'JPEG', quality=100, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optunaで学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "[3] label -> ex: 3 \n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_steps_per_epoch : 500\n",
      "valid_steps_per_epoch : 100\n"
     ]
    }
   ],
   "source": [
    "# モジュールimport\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py')\n",
    "from dataset import plot_log, prepare_data, util, plot_12task_log, util\n",
    "from transformer import get_train_valid_test, my_generator\n",
    "from model import define_model, multi_loss, my_callback, my_metric\n",
    "from predicter import roc_curve, conf_matrix, multi_predict, grad_cam, ensemble_predict, base_predict\n",
    "from tuning import optuna_train_base, optuna_train_Tox21, optuna_util\n",
    "\n",
    "sys.path.append(r'C:\\Users\\shingo\\Git\\keras-squeeze-excite-network')\n",
    "import se_inception_v3, se_densenet, se_inception_resnet_v2, se_resnet, se_resnext, se\n",
    "\n",
    "import keras\n",
    "import optuna\n",
    "import numpy as np\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(y_train.shape[0], 'train samples')\n",
    "print(y_test.shape[0], 'test samples')\n",
    "print(y_test[0], 'label -> ex: 3 ')\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print(y_test[0])\n",
    "\n",
    "\n",
    "# 画像管理クラス\n",
    "d_cls=get_train_valid_test.LabeledDataset([32, 32, 3]\n",
    "                                          , 100\n",
    "                                          , valid_batch_size=100\n",
    "                                          , test_batch_size=100\n",
    "                                          , train_samples = 50000\n",
    "                                          , valid_samples = 10000 \n",
    "                                         )\n",
    "d_cls.X_train = x_train/255.0\n",
    "d_cls.y_train = y_train\n",
    "d_cls.X_valid = x_test/255.0\n",
    "d_cls.y_valid = y_test\n",
    "\n",
    "# 基本コールバック\n",
    "def get_cb(output_dir, cosine_annealing_num_epoch=None):\n",
    "    cb = []\n",
    "\n",
    "    # ログを保存するカスタムコールバック\n",
    "    cb.append(my_callback.tsv_logger(os.path.join(output_dir, 'tsv_logger.tsv')))\n",
    "    \n",
    "    # epochごとに学習曲線保存する自作callback\n",
    "    cb.append(my_callback.learning_curve_plot(os.path.join(output_dir, 'learning_curve.png')))\n",
    "    \n",
    "    # 各エポックでval_lossが最小となるモデル保存\n",
    "    cb.append(keras.callbacks.ModelCheckpoint(filepath=os.path.join(output_dir, 'finetuning.h5'), monitor='val_loss', save_best_only=True, verbose=1))\n",
    "\n",
    "    # 過学習の抑制 <early_stopping_pati>step続けてval_loss減らなかったら打ち切る\n",
    "    cb.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1))\n",
    "    \n",
    "    return cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的関数の定義\n",
    "#### チューニング可能パラメータ\n",
    "- モデル（ニューラルネットワーク）\n",
    "    - Imagenetの学習済みモデル\n",
    "    - fine-tuning\n",
    "    - 全結合0-5層（重みの初期値はhe_normal(He の正規分布)で固定）\n",
    "        - ユニット数 (同じ値か層ごとに減らす)\n",
    "        - dropout_rate (全層同じ値になる)\n",
    "        - Batch_Normalization (全層同じ値になる)\n",
    "        - l2正則化(weight decay) (全層同じ値になる)\n",
    "- オプティマイザ\n",
    "- 学習率\n",
    "    - 学習率変更なし\n",
    "    - cosine_annealing(factor=0.01, epochs=None)\n",
    "    - LearningRateScheduler(lr* 1/4 を3回する)\n",
    "- データ水増し( keras.preprocessing.image.ImageDataGenerator )\n",
    "    - 画像の剪断(shear)\n",
    "    - 拡大縮小(zoom)\n",
    "    - 回転(rotation)\n",
    "    - 上下反転(vertical_flip)\n",
    "    - 左右反転(horizontal_flip)\n",
    "    - 画像の一部矩形領域を隠す（random_erasing)\n",
    "    - 画像混ぜる(mix_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力ディレクトリ\n",
    "output_dir = r'D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_from_02_keras_py\\optuna'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "## best_parameter をval_loss でとる\n",
    "return_val_loss=True\n",
    "\n",
    "### チューニング可能パラメータ引数 ###\n",
    "## model param\n",
    "choice_model = ['OctConv_WideResNet']#['VGG16']# 学習済みモデル\n",
    "trainable = [15, 'all'] # 重みは全層学習させる（重みunfreeze開始レイヤーを番号で指定できる）\n",
    "FCnum = [0,1,4] # FC層の数\n",
    "Dence = [1024, 512, 256, 128] # FC層のユニット数\n",
    "Dropout = [0.0, 0.5] # FC層のDropout\n",
    "addBatchNorm = [None] # FC層のBatchNorm\n",
    "l2 = [0.0, 1e-4] # FC層のl2\n",
    "choice_optim = ['sgd', 'adam', 'nadam'] # optimizer\n",
    "lr = [0.0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1] # （初期）学習率\n",
    "callback_lr = [None, 'cosine_annealing'] # 学習率変更するcallback\n",
    "callback_save_model=True # モデル保存するcallback つけるか. False なら保存しない\n",
    "\n",
    "if callback_save_model == True:\n",
    "    model_dir = os.path.join(output_dir, 'model_weight_optuna')\n",
    "\n",
    "## ImageDataGenerator param\n",
    "rescale=1.0 # 画像の前処理\n",
    "horizontal_flip=[True] # 画像の左右反転\n",
    "vertical_flip=[True, False] # 画像の上下反転\n",
    "# 画像の回転の下限角、回転の上限角、回転角の刻み幅\n",
    "rotation_range_min=0 \n",
    "rotation_range_max=180\n",
    "rotation_unit=10 # 0.0 にしたら rotation_range_max で固定\n",
    "# 画像の縮小の最少-最大倍率、拡大の最少-最大倍率、縮小拡大倍率の刻み幅\n",
    "zoom_range_low_min=0.5\n",
    "zoom_range_low_max=1.0\n",
    "zoom_range_high_min=1.0\n",
    "zoom_range_high_max=1.5\n",
    "zoom_range_unit=1.0 # 0.0 にしたら zoom_range_low_min, zoom_range_high_max で固定\n",
    "# 画像のせん断の最少倍率、せん断の最大倍率、せん断倍率の刻み幅\n",
    "shear_range_min=0.0\n",
    "shear_range_max=0.5\n",
    "shear_range_unit=0.1 # 0.0 にしたら shear_range_max で固定\n",
    "random_eraser_flg= [True, False] # Random Erasing 含めるか\n",
    "pixel_min=np.min(d_cls.X_train) # Random Erasing で使う画素数の最小値\n",
    "pixel_max=np.max(d_cls.X_train) # Random Erasing で使う画像数の最大値（1/255で割ってるはずだから基本1.0）\n",
    "# mixup 含めるか\n",
    "use_mixup=[True, False]\n",
    "\n",
    "# パラメータを引数に持たせてoptunaの目的関数を定義\n",
    "objective = optuna_train_Tox21.Objective(out_dir=output_dir\n",
    "                                        , d_cls=d_cls\n",
    "                                        , shape=[32, 32, 3]\n",
    "                                        , num_classes=10\n",
    "                                        , epochs=1\n",
    "                                        , gpu_count=1\n",
    "                                        , loss='categorical_crossentropy'\n",
    "                                        , metrics=['acc']\n",
    "                                        , verbose=2\n",
    "                                        , activation='softmax'\n",
    "                                        , pred_kernel_initializer='zeros'\n",
    "                                        , pred_l2_rate=0.0001\n",
    "                                        , FCpool='GlobalAveragePooling2D'\n",
    "                                        , return_val_loss=return_val_loss\n",
    "                                        , callbacks=get_cb(output_dir, cosine_annealing_num_epoch=None)\n",
    "                                        , callback_save_model=callback_save_model\n",
    "                                        , choice_model=choice_model\n",
    "                                        , trainable=trainable\n",
    "                                        , FCnum=FCnum\n",
    "                                        , Dence=Dence\n",
    "                                        , Dropout=Dropout\n",
    "                                        , addBatchNorm=addBatchNorm\n",
    "                                        , l2=l2\n",
    "                                        , choice_optim=choice_optim\n",
    "                                        , lr=lr\n",
    "                                        , callback_lr=callback_lr\n",
    "                                        , horizontal_flip=horizontal_flip\n",
    "                                        , vertical_flip=vertical_flip\n",
    "                                        , rotation_range_min=rotation_range_min\n",
    "                                        , rotation_range_max=rotation_range_max\n",
    "                                        , rotation_unit=rotation_unit\n",
    "                                        , zoom_range_low_min=zoom_range_low_min\n",
    "                                        , zoom_range_low_max=zoom_range_low_max\n",
    "                                        , zoom_range_high_min=zoom_range_high_min\n",
    "                                        , zoom_range_high_max=zoom_range_high_max\n",
    "                                        , zoom_range_unit=zoom_range_unit\n",
    "                                        , shear_range_min=shear_range_min\n",
    "                                        , shear_range_max=shear_range_max\n",
    "                                        , shear_range_unit=shear_range_unit\n",
    "                                        , random_eraser_flg=random_eraser_flg\n",
    "                                        , pixel_min=pixel_min\n",
    "                                        , pixel_max=pixel_max\n",
    "                                        , use_mixup=use_mixup\n",
    "                                        , branch_Tox21_12task=[False]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-07-06 22:56:41,077] A new study created with name: example-study\n",
      "[W 2019-07-06 22:56:43,504] Setting status of trial#0 as TrialState.FAIL because of the following error: ValueError('tuple.index(x): x not in tuple',)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\study.py\", line 468, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning\\optuna_train_Tox21.py\", line 401, in __call__\n",
      "    model, orig_model = self._optuna_model(trial, branch_Tox21_12task)\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning\\optuna_train_Tox21.py\", line 192, in _optuna_model\n",
      "    trainable = trial.suggest_categorical('trainable', self.trainable)\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\trial.py\", line 337, in suggest_categorical\n",
      "    return self._suggest(name, distributions.CategoricalDistribution(choices=choices))\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\trial.py\", line 457, in _suggest\n",
      "    return self._set_new_param_or_get_existing(name, param_value, distribution)\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\trial.py\", line 462, in _set_new_param_or_get_existing\n",
      "    param_value_in_internal_repr = distribution.to_internal_repr(param_value)\n",
      "  File \"C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\distributions.py\", line 236, in to_internal_repr\n",
      "    return self.choices.index(param_value_in_external_repr)\n",
      "ValueError: tuple.index(x): x not in tuple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- model_param -----\n",
      "output_dir = D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_from_02_keras_py\\optuna\n",
      "img_rows img_cols channels = 32 32 3\n",
      "num_classes = 10\n",
      "choice_model trainable = OctConv_WideResNet all\n",
      "FCnum = 4\n",
      "FCpool = GlobalAveragePooling2D\n",
      "pred_kernel_initializer pred_l2_rate = zeros 0.0001\n",
      "activation = softmax\n",
      "gpu_count = 1\n",
      "skip_bn = True\n",
      "oct_conv_alpha, wrn_N, wrn_k = 0.25 4 10\n",
      "16\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "640\n",
      "640\n",
      "640\n",
      "640\n",
      "640\n",
      "640\n",
      "640\n",
      "----- FC_layer -----\n",
      "dence dropout addBatchNorm kernel_initializer l2_rate = 256 0.5 None he_normal 0.0001\n",
      "dence dropout addBatchNorm kernel_initializer l2_rate = 192 0.5 None he_normal 0.0001\n",
      "dence dropout addBatchNorm kernel_initializer l2_rate = 144 0.5 None he_normal 0.0001\n",
      "dence dropout addBatchNorm kernel_initializer l2_rate = 108 0.5 None he_normal 0.0001\n",
      "---- choice_optim = sgd ----\n",
      "sgd_lr sgd_momentum sgd_decay sgd_nesterov = 0.01 0.9 0.0 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-07-06 22:56:57,908] The range of parameter `zoom_range_low` is not divisible by `q`, and is replaced by [0.5, 0.5].\n",
      "[W 2019-07-06 22:56:58,083] The range of parameter `zoom_range_high` is not divisible by `q`, and is replaced by [1.0, 1.0].\n",
      "[W 2019-07-06 22:56:58,240] The range of parameter `shear_range` is not divisible by `q`, and is replaced by [0.0, 0.4].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- train_ImageDataGenerator -----\n",
      "use_mixup: False\n",
      "IDG_options: {'horizontal_flip': True, 'vertical_flip': False, 'rotation_range': 90.0, 'zoom_range': [0.5, 1.0], 'shear_range': 0.0, 'preprocessing_function': <function get_random_eraser.<locals>.eraser at 0x00000261DCD8F840>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-07-06 22:56:59,401] The use of `Trial.trial_id` is deprecated. Please use `Trial.number` instead.\n",
      "[W 2019-07-06 22:56:59,413] The use of `Trial.trial_id` is deprecated. Please use `Trial.number` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch)\u001b[0m\n\u001b[0;32m    392\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     def _optimize_parallel(\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning/../Git/optuna\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\tuning\\optuna_train_Tox21.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    426\u001b[0m                                       \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                                       \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                                       \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;31m# verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m                                      )\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sqlite 使って履歴ファイル作る\n",
    "sqllite_path = output_dir+'/example.db'\n",
    "if os.path.exists(sqllite_path) == True:\n",
    "    os.remove(sqllite_path) # sqllite_pathすでにあれば一旦削除\n",
    "study = optuna.create_study(study_name='example-study', storage='sqlite:///'+sqllite_path)\n",
    "\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th colspan=\"5\" halign=\"left\">params</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">user_attrs</th>\n",
       "      <th>intermediate_values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Dence_1</th>\n",
       "      <th>Dence_2</th>\n",
       "      <th>Dence_3</th>\n",
       "      <th>Dence_4</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>loss</th>\n",
       "      <th>metrics</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>out_dir</th>\n",
       "      <th>pred_kernel_initializer</th>\n",
       "      <th>pred_l2_rate</th>\n",
       "      <th>shape</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>2.885443</td>\n",
       "      <td>2019-01-22 00:08:01.613087</td>\n",
       "      <td>2019-01-22 00:08:44.498513</td>\n",
       "      <td>256</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.876772</td>\n",
       "      <td>['acc']</td>\n",
       "      <td>10</td>\n",
       "      <td>D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...</td>\n",
       "      <td>zeros</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[32, 32, 3]</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2.885443</td>\n",
       "      <td>2.885443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>0.325050</td>\n",
       "      <td>2019-01-22 00:08:44.686856</td>\n",
       "      <td>2019-01-22 00:09:28.035780</td>\n",
       "      <td>1024</td>\n",
       "      <td>768.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325071</td>\n",
       "      <td>['acc']</td>\n",
       "      <td>10</td>\n",
       "      <td>D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...</td>\n",
       "      <td>zeros</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[32, 32, 3]</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.325050</td>\n",
       "      <td>0.325050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_id                state     value             datetime_start  \\\n",
       "                                                                       \n",
       "0        1  TrialState.COMPLETE  2.885443 2019-01-22 00:08:01.613087   \n",
       "1        2  TrialState.COMPLETE  0.325050 2019-01-22 00:08:44.686856   \n",
       "\n",
       "           datetime_complete  params                                  \\\n",
       "                             Dence_1 Dence_2 Dence_3 Dence_4 Dropout   \n",
       "0 2019-01-22 00:08:44.498513     256   128.0    64.0    64.0     0.5   \n",
       "1 2019-01-22 00:09:28.035780    1024   768.0   384.0   192.0     0.5   \n",
       "\n",
       "          ...         user_attrs                       \\\n",
       "          ...               loss  metrics num_classes   \n",
       "0         ...           2.876772  ['acc']          10   \n",
       "1         ...           0.325071  ['acc']          10   \n",
       "\n",
       "                                                                              \\\n",
       "                                             out_dir pred_kernel_initializer   \n",
       "0  D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...                   zeros   \n",
       "1  D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...                   zeros   \n",
       "\n",
       "                                              intermediate_values  \n",
       "  pred_l2_rate        shape val_acc  val_loss                   0  \n",
       "0       0.0001  [32, 32, 3]  0.9000  2.885443            2.885443  \n",
       "1       0.0001  [32, 32, 3]  0.8097  0.325050            0.325050  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 試行結果データフレームで出力\n",
    "study = optuna.Study(study_name='example-study', storage='sqlite:///'+sqllite_path)\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(os.path.join(output_dir, 'optuna_lgb.tsv'), sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dence_1': 1024,\n",
       " 'Dence_2': 768.0,\n",
       " 'Dence_3': 384.0,\n",
       " 'Dence_4': 192.0,\n",
       " 'Dropout': 0.5,\n",
       " 'FCnum': 4,\n",
       " 'addBatchNorm': None,\n",
       " 'branch_Tox21_12task': False,\n",
       " 'callback_lr': None,\n",
       " 'choice_model': 'VGG16',\n",
       " 'choice_optim': 'sgd',\n",
       " 'horizontal_flip': True,\n",
       " 'l2': 0.0,\n",
       " 'lr': 0.0001,\n",
       " 'random_eraser_flg': True,\n",
       " 'rotation_range': 160.0,\n",
       " 'shear_range': 0.4,\n",
       " 'trainable': 15,\n",
       " 'use_mixup': False,\n",
       " 'vertical_flip': True,\n",
       " 'zoom_range_high': 1.0,\n",
       " 'zoom_range_low': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# study.best_params ファイル出力\n",
    "f = open(os.path.join(output_dir, 'best_params.txt'), 'w') # 書き込みモードで開く\n",
    "for key,value in sorted(study.best_params.items()):\n",
    "    f.write('{0}\\t{1}\\n'.format(key, value))\n",
    "f.close() # ファイル閉じる\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(trial_id=2, state=<TrialState.COMPLETE: 1>, value=0.3250504344701767, datetime_start=datetime.datetime(2019, 1, 22, 0, 8, 44, 686856), datetime_complete=datetime.datetime(2019, 1, 22, 0, 9, 28, 35780), params={'Dence_1': 1024, 'Dence_2': 768.0, 'Dence_3': 384.0, 'Dence_4': 192.0, 'Dropout': 0.5, 'FCnum': 4, 'addBatchNorm': None, 'branch_Tox21_12task': False, 'callback_lr': None, 'choice_model': 'VGG16', 'choice_optim': 'sgd', 'horizontal_flip': True, 'l2': 0.0, 'lr': 0.0001, 'random_eraser_flg': True, 'rotation_range': 160.0, 'shear_range': 0.4, 'trainable': 15, 'use_mixup': False, 'vertical_flip': True, 'zoom_range_high': 1.0, 'zoom_range_low': 1.0}, user_attrs={'FCpool': 'GlobalAveragePooling2D', 'acc': 0.8961800001561642, 'activation': 'softmax', 'callbacks': '[<model.my_callback.tsv_logger.<locals>._TSVLogger object at 0x000002091A5C5278>, <model.my_callback.learning_curve_plot.<locals>._LearningCurvePlotter object at 0x000002091A5C5208>, <keras.callbacks.ModelCheckpoint object at 0x000002091A5C51D0>, <keras.callbacks.EarlyStopping object at 0x000002091A5C5438>]', 'gpu_count': '1', 'loss': 0.3250714740753174, 'metrics': \"['acc']\", 'num_classes': '10', 'out_dir': 'D:\\\\work\\\\kaggle_data\\\\CIFAR10\\\\results\\\\VGG16+FC1_from_02_keras_py\\\\optuna', 'pred_kernel_initializer': 'zeros', 'pred_l2_rate': '0.0001', 'shape': '[32, 32, 3]', 'val_acc': 0.8096999999880791, 'val_loss': 0.3250504344701767}, system_attrs={}, intermediate_values={0: 0.3250504344701767}, params_in_internal_repr={'Dence_1': 0.0, 'Dence_2': 768.0, 'Dence_3': 384.0, 'Dence_4': 192.0, 'Dropout': 1.0, 'FCnum': 2.0, 'addBatchNorm': 0.0, 'branch_Tox21_12task': 0.0, 'callback_lr': 0.0, 'choice_model': 0.0, 'choice_optim': 0.0, 'horizontal_flip': 0.0, 'l2': 0.0, 'lr': 2.0, 'random_eraser_flg': 0.0, 'rotation_range': 160.0, 'shear_range': 0.4, 'trainable': 0.0, 'use_mixup': 1.0, 'vertical_flip': 0.0, 'zoom_range_high': 1.0, 'zoom_range_low': 1.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>params</th>\n",
       "      <th>params.1</th>\n",
       "      <th>params.2</th>\n",
       "      <th>params.3</th>\n",
       "      <th>...</th>\n",
       "      <th>user_attrs.5</th>\n",
       "      <th>user_attrs.6</th>\n",
       "      <th>user_attrs.7</th>\n",
       "      <th>user_attrs.8</th>\n",
       "      <th>user_attrs.9</th>\n",
       "      <th>user_attrs.10</th>\n",
       "      <th>user_attrs.11</th>\n",
       "      <th>user_attrs.12</th>\n",
       "      <th>user_attrs.13</th>\n",
       "      <th>intermediate_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dence_1</td>\n",
       "      <td>Dence_2</td>\n",
       "      <td>Dence_3</td>\n",
       "      <td>Dence_4</td>\n",
       "      <td>...</td>\n",
       "      <td>loss</td>\n",
       "      <td>metrics</td>\n",
       "      <td>num_classes</td>\n",
       "      <td>out_dir</td>\n",
       "      <td>pred_kernel_initializer</td>\n",
       "      <td>pred_l2_rate</td>\n",
       "      <td>shape</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>2.885443</td>\n",
       "      <td>2019-01-22 00:08:01.613087</td>\n",
       "      <td>2019-01-22 00:08:44.498513</td>\n",
       "      <td>256</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.876772137582302</td>\n",
       "      <td>['acc']</td>\n",
       "      <td>10</td>\n",
       "      <td>D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...</td>\n",
       "      <td>zeros</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[32, 32, 3]</td>\n",
       "      <td>0.8999999997578562</td>\n",
       "      <td>2.8854430747032165</td>\n",
       "      <td>2.885443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>0.325050</td>\n",
       "      <td>2019-01-22 00:08:44.686856</td>\n",
       "      <td>2019-01-22 00:09:28.035780</td>\n",
       "      <td>1024</td>\n",
       "      <td>768.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3250714740753174</td>\n",
       "      <td>['acc']</td>\n",
       "      <td>10</td>\n",
       "      <td>D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...</td>\n",
       "      <td>zeros</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[32, 32, 3]</td>\n",
       "      <td>0.8096999999880791</td>\n",
       "      <td>0.3250504344701767</td>\n",
       "      <td>0.325050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  trial_id                state     value  \\\n",
       "0         NaN       NaN                  NaN       NaN   \n",
       "1         0.0       1.0  TrialState.COMPLETE  2.885443   \n",
       "2         1.0       2.0  TrialState.COMPLETE  0.325050   \n",
       "\n",
       "               datetime_start           datetime_complete   params params.1  \\\n",
       "0                         NaN                         NaN  Dence_1  Dence_2   \n",
       "1  2019-01-22 00:08:01.613087  2019-01-22 00:08:44.498513      256    128.0   \n",
       "2  2019-01-22 00:08:44.686856  2019-01-22 00:09:28.035780     1024    768.0   \n",
       "\n",
       "  params.2 params.3         ...                user_attrs.5 user_attrs.6  \\\n",
       "0  Dence_3  Dence_4         ...                        loss      metrics   \n",
       "1     64.0     64.0         ...           2.876772137582302      ['acc']   \n",
       "2    384.0    192.0         ...          0.3250714740753174      ['acc']   \n",
       "\n",
       "  user_attrs.7                                       user_attrs.8  \\\n",
       "0  num_classes                                            out_dir   \n",
       "1           10  D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...   \n",
       "2           10  D:\\work\\kaggle_data\\CIFAR10\\results\\VGG16+FC1_...   \n",
       "\n",
       "              user_attrs.9 user_attrs.10 user_attrs.11       user_attrs.12  \\\n",
       "0  pred_kernel_initializer  pred_l2_rate         shape             val_acc   \n",
       "1                    zeros        0.0001   [32, 32, 3]  0.8999999997578562   \n",
       "2                    zeros        0.0001   [32, 32, 3]  0.8096999999880791   \n",
       "\n",
       "        user_attrs.13 intermediate_values  \n",
       "0            val_loss            0.000000  \n",
       "1  2.8854430747032165            2.885443  \n",
       "2  0.3250504344701767            0.325050  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trial結果ロード\n",
    "import pandas as pd\n",
    "result_df = pd.read_table(os.path.join(output_dir, 'optuna_lgb.tsv'))\n",
    "# optunaのtrial結果plot\n",
    "optuna_util.trial_plot(output_dir, result_df, epochs=1, val_name=\"val_loss\", trial_id=None)# , trial_id=None # , trial_id=2 # , trial_id=[2,45,46,47,48,49]\n",
    "result_df\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
