{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/shingo/jupyter_notebook/tfgpu_py36_work/02_keras_py/experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shingo\\\\Anaconda3\\\\envs\\\\tfgpu20\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"Red\">マルチラベルで分類モデル作成<font>\n",
    "## ニューラルネットワークを分岐させずにMulti-task learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#gpu_num = \"3\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モジュールimport\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py')\n",
    "\n",
    "from dataset import plot_log, prepare_data, util\n",
    "\n",
    "from transformer import tf_get_train_valid_test as get_train_valid_test\n",
    "from transformer import tf_my_generator as my_generator\n",
    "\n",
    "from model import tf_define_model as define_model\n",
    "from model import tf_multi_loss as multi_loss\n",
    "from model import tf_my_callback as my_callback\n",
    "from model import my_metric\n",
    "\n",
    "from predicter import roc_curve, conf_matrix, ensemble_predict\n",
    "from predicter import tf_grad_cam as grad_cam\n",
    "from predicter import tf_base_predict as  base_predict\n",
    "\n",
    "#from tuning import optuna_train_base, optuna_train_Tox21\n",
    "\n",
    "import pathlib\n",
    "#current_dir = pathlib.Path(\"__file__\").resolve().parent\n",
    "#sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\Git\\keras-squeeze-excite-network')\n",
    "#import se_inception_v3, se_densenet, se_inception_resnet_v2, se_resnet, se_resnext, se\n",
    "\n",
    "sys.path.append(r'C:\\Users\\shingo\\Git\\mixup-generator')\n",
    "from mixup_generator import MixupGenerator\n",
    "from random_eraser import get_random_eraser\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチラベルサンプルデータ\n",
    "- https://blog.manash.me/multi-task-learning-in-keras-implementation-of-multi-task-classification-loss-f1d42da5c3f6\n",
    "- classes = np.array(['desert', 'mountain', 'sea', 'sunset', 'trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 100, 100, 3) (400, 100, 100, 3)\n",
      "[[0 0 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x224d8e66e08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading and Viewing the dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Jupyterでインライン表示するための宣言\n",
    "%matplotlib inline\n",
    "\n",
    "def load():\n",
    "    f = h5py.File(\"01_code_test/dataset.h5\")\n",
    "    x = f['x'].value\n",
    "    y = f['y'].value\n",
    "    f.close()\n",
    "    \n",
    "    x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100)\n",
    "    \n",
    "    # Making the data channel last\n",
    "    x_train = np.rollaxis(x_train, 1, 4)\n",
    "    x_test = np.rollaxis(x_test, 1, 4)\n",
    "    \n",
    "    # Normalizing data\n",
    "    x_train = x_train  / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "   \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = load()\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train[:5])\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータ設定\n",
    "- 画像サイズ: 100x100\n",
    "- エポック数: 10\n",
    "- モデル（ニューラルネットワーク）\n",
    "    - Imagenetの学習済みモデル: SEInceptionV3\n",
    "    - 全結合層: 1層（各層のニューロンの数は1024。各層にdropoutを0.5倍、重みの初期値はhe_normal(He の正規分布)、L2正則化=1e-4）\n",
    "    - 重みは全層学習させる（fine-tuningなし）\n",
    "    - 出力層の活性化関数: sigmoid（マルチラベルなので）\n",
    "    - 出力層の重みの初期値はzero\n",
    "- オプティマイザ: SGD\n",
    "    - 学習率: 0.01\n",
    "- データ水増し\n",
    "    - 画像の剪断（shear_range=0.2）\n",
    "    - 拡大縮小（zoom_range=[0.5, 1.9]）\n",
    "    - 回転（rotation_range=60）\n",
    "    - 上下反転（horizontal_flip=True）\n",
    "    - 左右反転（vertical_flip=True）\n",
    "    - 画像の一部矩形領域を隠す（random_erasing)\n",
    "- callback\n",
    "    - keras.callbacks.TerminateOnNaN: lossがNaNになった時に訓練を終了する\n",
    "    - keras.callbacks.ModelCheckpoint: val_loss最少になるモデルを保存する\n",
    "    - keras.callbacks.EarlyStopping: val_lossが100エポック更新されなければ学習停止する\n",
    "    - cosine_annealing: lr*0.01 になるまで段階的に学習率下げる\n",
    "    - keras.callbacks.CSVLogger: 各エポックの結果をcsvファイルに保存する\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_count: 1\n"
     ]
    }
   ],
   "source": [
    "# 出力ディレクトリ\n",
    "out_dir = r'D:\\work\\kaggle_data\\tf_multi_label_test'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# batch_size\n",
    "train_batch_size=50\n",
    "valid_batch_size=50\n",
    "\n",
    "# エポック数\n",
    "epochs=10#250\n",
    "\n",
    "# 入力層のサイズ\n",
    "shape=[100, 100, 3]\n",
    "\n",
    "# クラス数\n",
    "num_classes=5\n",
    "task_name_list=['desert', 'mountain', 'sea', 'sunset', 'trees']\n",
    "\n",
    "# Fine-tuning する学習済みモデル\n",
    "#choice_model='EfficientNet'# ['VGG16','ResNet50','InceptionV3','Xception','InceptionResNetV2','NASNetLarge','SEResNet154','SEInceptionV3','SEInceptionResNetV2']\n",
    "choice_model='VGG16'\n",
    "\n",
    "# 重みは全層学習させる（重みunfreeze開始レイヤーを番号で指定できる）\n",
    "trainable='all'# [249]\n",
    "\n",
    "# GradCamでモデルの注目点を切りだす最後の畳み込み層\n",
    "layer_name = 'top_activation' #'mixed10'\n",
    "\n",
    "## 全結合層のパラメータ\n",
    "# pooling方法\n",
    "fcpool='GlobalAveragePooling2D'\n",
    "# 全結像層\n",
    "fcs = [1024]\n",
    "# 全結合層のニューロンの数とdropout rate\n",
    "drop, is_add_batchnorm, kernel_init, l2_rate = 0.5, True, 'he_normal', 1e-4\n",
    "\n",
    "# 出力層の活性化関数\n",
    "activation = 'sigmoid'\n",
    "pred_kernel_initializer='zeros'\n",
    "pred_l2_rate=1e-4\n",
    "\n",
    "# optimizer のパラメータ\n",
    "choice_optim='sgd'\n",
    "lr = 0.01\n",
    "decay = 0.0\n",
    "\n",
    "# GPUの数\n",
    "gpu_num = '1'\n",
    "gpu_count=len(gpu_num.split(','))\n",
    "print('gpu_count:', gpu_count)\n",
    "\n",
    "# ImageDataGenerator のデータ水増しオプション\n",
    "horizontal_flip=True\n",
    "vertical_flip=True\n",
    "rotation_range=60\n",
    "zoom_range=[0.5, 1.9]\n",
    "shear_range=0.2\n",
    "\n",
    "## コールバックの設定\n",
    "# keras.callbacks.ModelCheckpoint\n",
    "check_monitor='val_loss' # val_loss最少になるモデルを保存する\n",
    "\n",
    "# keras.callbacks.EarlyStopping\n",
    "early_monitor='val_loss' # val_lossが100エポック更新されなければ学習停止する\n",
    "early_stopping_pati=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- model_param -----\n",
      "output_dir = D:\\work\\kaggle_data\\tf_multi_label_test\n",
      "img_rows img_cols channels = 100 100 3\n",
      "num_classes = 5\n",
      "choice_model trainable = VGG16 all\n",
      "fcs = [1024]\n",
      "fcpool = GlobalAveragePooling2D\n",
      "pred_kernel_initializer pred_l2_rate = zeros 0.0001\n",
      "activation = sigmoid\n",
      "gpu_count = 1\n",
      "skip_bn = True\n",
      "n_multitask = 1\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "----- FC_layers -----\n",
      "dence dropout is_add_batchnorm kernel_initializer l2_rate = 1024 0.5 True he_normal 0.0001\n",
      "---- choice_optim = sgd ----\n",
      "sgd_lr sgd_momentum sgd_decay sgd_nesterov = 0.01 0.9 0.0 True\n",
      "[<tensorflow.python.keras.callbacks.TerminateOnNaN object at 0x00000226798B0248>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x0000022679924688>, <tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000022679937208>, <model.tf_my_callback.cosine_annealing.<locals>._CosineAnnealing object at 0x0000022679937148>, <model.tf_my_callback.learning_curve_plot.<locals>._LearningCurvePlotter object at 0x00000226799370C8>, <model.tf_my_callback.tsv_logger.<locals>._TSVLogger object at 0x0000022679A54308>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x00000226799373C8>]\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model, orig_model = define_model.get_fine_tuning_model(out_dir, shape[0], shape[1], shape[2], num_classes\n",
    "                                                        , choice_model, trainable\n",
    "                                                        , fcs=fcs\n",
    "                                                        , fcpool=fcpool\n",
    "                                                        , drop=drop, is_add_batchnorm=is_add_batchnorm, kernel_init=kernel_init, l2_rate=l2_rate\n",
    "                                                        , pred_kernel_initializer=pred_kernel_initializer, pred_l2_rate=pred_l2_rate\n",
    "                                                        , activation=activation \n",
    "                                                        , gpu_count=gpu_count\n",
    "                                                        #, skip_bn=skip_bn\n",
    "                                                        )\n",
    "# オプティマイザ\n",
    "optim = define_model.get_optimizers(choice_optim, lr=lr, decay=decay)\n",
    "#lr_metric = my_metric.get_lr_metric(optim)\n",
    "\n",
    "# モデルコンパイル\n",
    "model.compile(loss=multi_loss.build_masked_loss(K.binary_crossentropy),\n",
    "              optimizer=optim,\n",
    "              metrics=['binary_accuracy', multi_loss.masked_accuracy])#, lr_metric])\n",
    "\n",
    "# callback\n",
    "cb = []\n",
    "\n",
    "if gpu_count > 1:\n",
    "    # マルチGPUでModelCheckpoint使うためのコールバック\n",
    "    weight_dir = os.path.join(out_dir, 'model_weight')\n",
    "    os.makedirs(weight_dir, exist_ok=True)\n",
    "    cb.append(my_callback.MyCheckPoint(orig_model, weight_dir))\n",
    "    \n",
    "    # batch_sizeは並列で処理を行うために元々のbatch_sizeをGPUの数だけ掛ける\n",
    "    train_batch_size = train_batch_size * gpu_count\n",
    "    valid_batch_size = valid_batch_size * gpu_count\n",
    "else:\n",
    "    cb.append(keras.callbacks.TerminateOnNaN())\n",
    "    cb.append(keras.callbacks.ModelCheckpoint(filepath=os.path.join(out_dir, 'best_model.h5'), monitor=check_monitor, save_best_only=True))#, monitor='val_acc'\n",
    "    cb.append(keras.callbacks.EarlyStopping(monitor=early_monitor, patience=early_stopping_pati , verbose=1))\n",
    "    # 学習率をエポック増やすごとにコサインカーブのように上げ下げする\n",
    "    ## 引数なしならlr*0.01まで下げるだけ\n",
    "    cb.append(my_callback.cosine_annealing())\n",
    "    \n",
    "    # epochごとに学習曲線保存する自作callback\n",
    "    cb.append(my_callback.learning_curve_plot(os.path.join(out_dir, 'learning_curve.png')))\n",
    "    \n",
    "    # ログを保存するカスタムコールバック\n",
    "    cb.append(my_callback.tsv_logger(os.path.join(out_dir, 'tsv_logger.tsv')))\n",
    "    \n",
    "cb.append(keras.callbacks.CSVLogger(os.path.join(out_dir, 'history.tsv'), separator='\\t'))\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "FC_avg (GlobalAveragePooling (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FC0_dence (Dense)            (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "FC0_batchNormalization (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "FC0_act (Activation)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "FC0_dropout (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 15,249,221\n",
      "Trainable params: 15,247,173\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルのサマリー\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 FC_avg\n",
      "20 FC0_dence\n",
      "21 FC0_batchNormalization\n",
      "22 FC0_act\n",
      "23 FC0_dropout\n",
      "24 pred\n"
     ]
    }
   ],
   "source": [
    "# モデルのレイヤー名と番号\n",
    "count= 0\n",
    "for layer in model.layers:\n",
    "    print(count, layer.name)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ管理クラス定義\n",
    "- d_cls.X_train: train set の画像データ（d_cls.X_train.shape:[11764, 331, 331, 3]）\n",
    "- d_cls.X_valid: validation set の画像データ（d_cls.X_valid.shape:[296, 331, 331, 3]）\n",
    "- d_cls.X_test: test set の画像データ（d_cls.X_test.shape:[647, 331, 331, 3]）\n",
    "- d_cls.train_gen: train set のImageDataGenerator\n",
    "- d_cls.valid_gen: validation set のImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps_per_epoch : 32\n",
      "valid_steps_per_epoch : 8\n",
      "----- train_ImageDataGenerator -----\n",
      "use_mixup: False\n",
      "IDG_options: {'horizontal_flip': True, 'vertical_flip': True, 'rotation_range': 60, 'zoom_range': [0.5, 1.9], 'shear_range': 0.2}\n",
      "Wall time: 110 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator at 0x224d8ef6c88>,\n",
       " <keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator at 0x224d8ef69c8>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d_cls = get_train_valid_test.LabeledDataset(shape, train_batch_size, valid_batch_size\n",
    "                                            , train_samples=x_train.shape[0]\n",
    "                                            , valid_samples=x_test.shape[0]\n",
    "                                           )\n",
    "d_cls.X_train = x_train\n",
    "d_cls.y_train = y_train\n",
    "d_cls.X_valid = x_test\n",
    "d_cls.y_valid = y_test\n",
    "\n",
    "# ImageDataGenerator のオプションを辞書型で詰める\n",
    "# get_random_eraserでd_clsの値使うのでここで宣言しないとエラーになる\n",
    "IDG_options={'horizontal_flip': horizontal_flip\n",
    "             , 'vertical_flip': vertical_flip\n",
    "             , 'rotation_range': rotation_range\n",
    "             , 'zoom_range': zoom_range\n",
    "             , 'shear_range': shear_range\n",
    "             #, 'preprocessing_function': get_random_eraser(v_l=np.min(d_cls.X_train), v_h=np.max(d_cls.X_train))\n",
    "            }\n",
    "\n",
    "d_cls.create_generator(IDG_options=IDG_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[8.00035715e-01 6.94117665e-01 5.33333361e-01]\n",
      "   [8.03921580e-01 6.94117665e-01 5.33333361e-01]\n",
      "   [8.03921580e-01 6.94117665e-01 5.33333361e-01]\n",
      "   ...\n",
      "   [1.11454032e-01 3.69442254e-02 4.87089306e-02]\n",
      "   [7.20957369e-02 7.19279610e-03 1.57552138e-02]\n",
      "   [5.98993748e-02 2.17595361e-02 2.87697725e-02]]\n",
      "\n",
      "  [[8.00000012e-01 6.94351077e-01 5.33450067e-01]\n",
      "   [8.00324261e-01 6.94117665e-01 5.33333361e-01]\n",
      "   [8.03921580e-01 6.94117665e-01 5.33333361e-01]\n",
      "   ...\n",
      "   [1.01081260e-01 2.94893533e-02 4.02814262e-02]\n",
      "   [5.76954670e-02 7.57444650e-03 1.54175842e-02]\n",
      "   [8.01410899e-02 6.11549616e-02 6.49211034e-02]]\n",
      "\n",
      "  [[8.00269127e-01 7.02229917e-01 5.37524045e-01]\n",
      "   [8.00000012e-01 6.94117665e-01 5.33333361e-01]\n",
      "   [8.00612807e-01 6.94117665e-01 5.33333361e-01]\n",
      "   ...\n",
      "   [6.21547811e-02 8.85479618e-04 8.72861780e-03]\n",
      "   [6.59860149e-02 3.39328088e-02 3.99286076e-02]\n",
      "   [1.15826137e-01 1.09816387e-01 1.10338435e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.63804877e-01 8.27450991e-01 7.52198994e-01]\n",
      "   [8.69278669e-01 8.24838996e-01 7.68620253e-01]\n",
      "   [8.63836169e-01 8.12128007e-01 7.64584064e-01]\n",
      "   ...\n",
      "   [9.88048986e-02 1.14491172e-01 1.34099022e-01]\n",
      "   [1.41915470e-01 1.57601744e-01 1.77209586e-01]\n",
      "   [1.21568628e-01 1.37254909e-01 1.56862751e-01]]\n",
      "\n",
      "  [[8.67048979e-01 8.27068686e-01 7.61931241e-01]\n",
      "   [8.72522712e-01 8.23529422e-01 7.74483502e-01]\n",
      "   [7.21095979e-01 6.59655571e-01 6.05623424e-01]\n",
      "   ...\n",
      "   [8.66960213e-02 1.05882354e-01 1.11489974e-01]\n",
      "   [1.03133127e-01 1.18819401e-01 1.38427243e-01]\n",
      "   [1.39895633e-01 1.55581906e-01 1.75189748e-01]]\n",
      "\n",
      "  [[8.70293081e-01 8.23824584e-01 7.71663547e-01]\n",
      "   [8.19200814e-01 7.64449358e-01 7.14876533e-01]\n",
      "   [7.63763309e-01 7.09445834e-01 6.62971437e-01]\n",
      "   ...\n",
      "   [7.16646537e-02 1.05882354e-01 1.17108852e-01]\n",
      "   [8.69845748e-02 1.05882354e-01 1.12644166e-01]\n",
      "   [1.07461348e-01 1.23147622e-01 1.42755479e-01]]]\n",
      "\n",
      "\n",
      " [[[5.08684874e-01 5.20449579e-01 6.02802515e-01]\n",
      "   [5.14396906e-01 5.26161611e-01 6.08514547e-01]\n",
      "   [5.35003185e-01 5.46767890e-01 6.29120827e-01]\n",
      "   ...\n",
      "   [1.54866688e-02 9.50451288e-03 7.84313753e-02]\n",
      "   [6.82016984e-02 6.34939522e-02 1.36436060e-01]\n",
      "   [1.89484417e-01 1.89484417e-01 2.61147469e-01]]\n",
      "\n",
      "  [[5.10104775e-01 5.21869481e-01 6.04222417e-01]\n",
      "   [5.07746518e-01 5.19511223e-01 6.01864159e-01]\n",
      "   [5.26063442e-01 5.37828147e-01 6.20181084e-01]\n",
      "   ...\n",
      "   [1.23433866e-01 1.21794574e-01 1.93202451e-01]\n",
      "   [2.41648138e-01 2.41648138e-01 3.14845383e-01]\n",
      "   [3.09552014e-01 3.05319726e-01 3.81945670e-01]]\n",
      "\n",
      "  [[4.91362095e-01 5.03126800e-01 5.85479736e-01]\n",
      "   [5.10265827e-01 5.22030532e-01 6.04383469e-01]\n",
      "   [5.12413144e-01 5.24177849e-01 6.06530786e-01]\n",
      "   ...\n",
      "   [2.88713068e-01 2.88269699e-01 3.63001198e-01]\n",
      "   [3.26428503e-01 3.19127768e-01 3.97287935e-01]\n",
      "   [2.94679612e-01 2.80521542e-01 3.62110376e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.41475916e-01 3.55001777e-01 1.19643128e-02]\n",
      "   [6.32557988e-01 3.50205004e-01 6.47504954e-03]\n",
      "   [6.25700593e-01 3.44222844e-01 3.04637360e-03]\n",
      "   ...\n",
      "   [5.71984649e-01 2.41453812e-01 0.00000000e+00]\n",
      "   [5.39242089e-01 2.25498989e-01 0.00000000e+00]\n",
      "   [5.10421097e-01 2.21877217e-01 0.00000000e+00]]\n",
      "\n",
      "  [[6.29489481e-01 3.47136557e-01 4.94082225e-03]\n",
      "   [6.22632146e-01 3.42688620e-01 1.51214667e-03]\n",
      "   [6.11941755e-01 3.39259952e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [5.83837211e-01 2.43613780e-01 0.00000000e+00]\n",
      "   [5.57984769e-01 2.32120544e-01 0.00000000e+00]\n",
      "   [5.26590705e-01 2.23529413e-01 0.00000000e+00]]\n",
      "\n",
      "  [[6.19519532e-01 3.41154397e-01 0.00000000e+00]\n",
      "   [6.05804861e-01 3.37725729e-01 0.00000000e+00]\n",
      "   [5.95048010e-01 3.28381330e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [5.84536433e-01 2.36441508e-01 0.00000000e+00]\n",
      "   [5.76727390e-01 2.44615629e-01 0.00000000e+00]\n",
      "   [5.43984830e-01 2.27079913e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[5.13662696e-01 8.30338061e-01 7.49753714e-01]\n",
      "   [2.73636609e-01 7.19182074e-01 5.67249835e-01]\n",
      "   [1.55593276e-01 6.81017876e-01 4.63281423e-01]\n",
      "   ...\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]]\n",
      "\n",
      "  [[6.08574510e-01 8.92347097e-01 8.25683117e-01]\n",
      "   [3.29318196e-01 7.17916608e-01 6.03949070e-01]\n",
      "   [1.66982695e-01 7.16451645e-01 4.93653178e-01]\n",
      "   ...\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]]\n",
      "\n",
      "  [[6.38021827e-01 9.06167030e-01 8.45240355e-01]\n",
      "   [4.15875316e-01 7.66450286e-01 6.71523809e-01]\n",
      "   [2.16268003e-01 7.20485926e-01 5.29438674e-01]\n",
      "   ...\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]\n",
      "   [1.76470593e-01 4.78431374e-01 3.92156869e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   ...\n",
      "   [3.71748395e-02 1.06125236e-01 2.17572395e-02]\n",
      "   [6.11974522e-02 1.01960786e-01 4.92116511e-02]\n",
      "   [6.63588196e-02 9.47333425e-02 6.90490007e-02]]\n",
      "\n",
      "  [[6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   ...\n",
      "   [5.48917092e-02 1.45355448e-01 4.20050882e-02]\n",
      "   [5.23390174e-02 1.01960786e-01 3.90877277e-02]\n",
      "   [6.50933310e-02 9.72643271e-02 6.27215430e-02]]\n",
      "\n",
      "  [[6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   [6.66666701e-02 2.58823544e-01 1.80392161e-01]\n",
      "   ...\n",
      "   [7.26085752e-02 1.84585661e-01 6.22529387e-02]\n",
      "   [4.34805863e-02 1.01960786e-01 2.89638042e-02]\n",
      "   [6.38278425e-02 9.97953042e-02 5.63940927e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[9.80392173e-02 3.57118770e-02 2.27376781e-02]\n",
      "   [9.80392173e-02 4.36071828e-02 3.55675519e-02]\n",
      "   [9.80392173e-02 5.15024886e-02 4.83974218e-02]\n",
      "   ...\n",
      "   [7.28104651e-01 5.19390106e-01 4.13507700e-01]\n",
      "   [7.36530542e-01 5.30286014e-01 4.22805041e-01]\n",
      "   [7.40599155e-01 5.36388993e-01 4.26873684e-01]]\n",
      "\n",
      "  [[1.30089775e-01 3.13725509e-02 1.44158199e-03]\n",
      "   [1.21207558e-01 3.13725509e-02 5.38923498e-03]\n",
      "   [1.12325341e-01 3.13725509e-02 9.33688786e-03]\n",
      "   ...\n",
      "   [7.36464322e-01 5.30186653e-01 4.22738820e-01]\n",
      "   [7.40532935e-01 5.36289632e-01 4.26807463e-01]\n",
      "   [7.27476060e-01 5.54380476e-01 4.51426774e-01]]\n",
      "\n",
      "  [[2.83061087e-01 1.24952391e-01 7.11206794e-02]\n",
      "   [2.43584543e-01 1.00279555e-01 5.23693264e-02]\n",
      "   [2.04108030e-01 7.56067261e-02 3.36179733e-02]\n",
      "   ...\n",
      "   [7.40466714e-01 5.36190331e-01 4.26741242e-01]\n",
      "   [7.27740943e-01 5.54049373e-01 4.50963199e-01]\n",
      "   [7.11466372e-01 5.74392557e-01 4.79443699e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.00072455e-02 2.81068027e-01 1.79107219e-01]\n",
      "   [5.94924428e-02 2.42415920e-01 1.40455127e-01]\n",
      "   [3.69785130e-02 2.10080311e-01 1.08540624e-01]\n",
      "   ...\n",
      "   [8.80557150e-02 4.23382431e-01 3.19412172e-01]\n",
      "   [1.10080406e-01 4.57421422e-01 3.49448085e-01]\n",
      "   [1.20344318e-01 4.72806007e-01 3.64106983e-01]]\n",
      "\n",
      "  [[5.99891171e-02 2.43045047e-01 1.41084254e-01]\n",
      "   [3.68460678e-02 2.10212752e-01 1.08639963e-01]\n",
      "   [4.49833497e-02 2.02075481e-01 1.02536999e-01]\n",
      "   ...\n",
      "   [3.69672664e-02 3.50717187e-01 2.60111570e-01]\n",
      "   [6.37534782e-02 3.83998990e-01 2.90668488e-01]\n",
      "   [9.42793414e-02 4.19995040e-01 3.25593293e-01]]\n",
      "\n",
      "  [[3.67136225e-02 2.10345209e-01 1.08739294e-01]\n",
      "   [4.48509008e-02 2.02207923e-01 1.02636337e-01]\n",
      "   [5.59998676e-02 2.01097906e-01 1.02054797e-01]\n",
      "   ...\n",
      "   [7.74890184e-02 3.90003502e-01 2.92037308e-01]\n",
      "   [3.05481441e-02 3.38718534e-01 2.42296383e-01]\n",
      "   [4.04919237e-02 3.49965185e-01 2.55516857e-01]]]\n",
      "\n",
      "\n",
      " [[[8.15686285e-01 2.54901975e-01 1.17647061e-02]\n",
      "   [8.15686285e-01 2.54901975e-01 1.17647061e-02]\n",
      "   [8.15686285e-01 2.54901975e-01 1.17647061e-02]\n",
      "   ...\n",
      "   [8.33311677e-01 8.52919519e-01 8.49240303e-01]\n",
      "   [8.76905262e-01 8.90076637e-01 8.91363919e-01]\n",
      "   [9.05882359e-01 9.02926803e-01 9.07340944e-01]]\n",
      "\n",
      "  [[8.13856721e-01 2.53072441e-01 9.93516482e-03]\n",
      "   [8.15686285e-01 2.54901975e-01 1.17647061e-02]\n",
      "   [8.15686285e-01 2.54901975e-01 1.17647061e-02]\n",
      "   ...\n",
      "   [8.69883418e-01 8.86246562e-01 8.86895537e-01]\n",
      "   [9.04279053e-01 9.05007839e-01 9.08783615e-01]\n",
      "   [9.05882359e-01 8.87995660e-01 8.94898355e-01]]\n",
      "\n",
      "  [[8.12960982e-01 2.52176672e-01 9.03940201e-03]\n",
      "   [8.12934816e-01 2.52150506e-01 9.01324861e-03]\n",
      "   [8.15301180e-01 2.54516900e-01 1.13796229e-02]\n",
      "   ...\n",
      "   [8.97257209e-01 9.01177764e-01 9.04315233e-01]\n",
      "   [9.05882359e-01 8.91825736e-01 8.98090065e-01]\n",
      "   [8.90401542e-01 8.62227917e-01 8.71619105e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.66531515e-01 1.42664209e-01 5.81477489e-03]\n",
      "   [4.51573998e-01 1.50524676e-01 7.84313772e-03]\n",
      "   [4.40566123e-01 1.30600035e-01 7.84313772e-03]\n",
      "   ...\n",
      "   [6.68275476e-01 5.94385803e-01 6.00536287e-01]\n",
      "   [6.80452585e-01 5.97425878e-01 6.05269015e-01]\n",
      "   [6.87551677e-01 6.02158666e-01 6.10001802e-01]]\n",
      "\n",
      "  [[4.57319111e-01 1.52439713e-01 7.84313772e-03]\n",
      "   [4.38012749e-01 1.37621850e-01 7.84313772e-03]\n",
      "   [4.50520247e-01 1.03226215e-01 7.84313772e-03]\n",
      "   ...\n",
      "   [6.58080101e-01 5.98513126e-01 6.02434695e-01]\n",
      "   [6.62743986e-01 5.93463898e-01 5.98692477e-01]\n",
      "   [6.76942229e-01 5.95830262e-01 6.03425205e-01]]\n",
      "\n",
      "  [[4.35459346e-01 1.44643679e-01 7.84313772e-03]\n",
      "   [4.47966844e-01 1.10248037e-01 7.84313772e-03]\n",
      "   [5.05570650e-01 1.20948702e-01 4.10719849e-02]\n",
      "   ...\n",
      "   [6.65388405e-01 6.16538465e-01 6.18755698e-01]\n",
      "   [6.60845876e-01 6.04044616e-01 6.07966185e-01]\n",
      "   [6.57212496e-01 5.92541993e-01 5.96848607e-01]]]\n",
      "\n",
      "\n",
      " [[[8.55503798e-01 4.82052028e-01 3.14026415e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   ...\n",
      "   [5.57042547e-02 1.38859496e-01 1.07486933e-01]\n",
      "   [6.02667853e-02 1.31890088e-01 1.03199944e-01]\n",
      "   [4.43011038e-02 1.03590176e-01 7.79835880e-02]]\n",
      "\n",
      "  [[8.58390570e-01 4.80608642e-01 3.15469801e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   ...\n",
      "   [5.81634380e-02 1.33993432e-01 1.04251616e-01]\n",
      "   [5.48178479e-02 1.18313611e-01 9.16553512e-02]\n",
      "   [2.39822734e-02 7.51438141e-02 5.15691116e-02]]\n",
      "\n",
      "  [[8.61277342e-01 4.79165256e-01 3.16913188e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   [8.54901969e-01 4.82352942e-01 3.13725501e-01]\n",
      "   ...\n",
      "   [6.22272044e-02 1.29929677e-01 1.02219738e-01]\n",
      "   [3.44990157e-02 8.98672566e-02 6.52408749e-02]\n",
      "   [5.33283651e-02 9.83489677e-02 7.48195574e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.64406496e-01 2.97287047e-01 2.65914500e-01]\n",
      "   [3.31845671e-01 2.70440578e-01 2.33806446e-01]\n",
      "   [2.85377115e-01 2.31931910e-01 1.89130679e-01]\n",
      "   ...\n",
      "   [2.37261891e-01 5.13739467e-01 5.08243680e-01]\n",
      "   [2.42401227e-01 5.39019048e-01 5.17744422e-01]\n",
      "   [1.94805220e-01 5.05780458e-01 4.71963376e-01]]\n",
      "\n",
      "  [[3.43414098e-01 2.79905647e-01 2.45374873e-01]\n",
      "   [3.04307252e-01 2.47707039e-01 2.07009137e-01]\n",
      "   [2.48803213e-01 2.01453671e-01 1.54588670e-01]\n",
      "   ...\n",
      "   [2.28995144e-01 5.01405299e-01 4.98533577e-01]\n",
      "   [2.51851976e-01 5.42919636e-01 5.25751770e-01]\n",
      "   [1.98631003e-01 5.04002869e-01 4.76892203e-01]]\n",
      "\n",
      "  [[3.21063370e-01 2.61618704e-01 2.23024160e-01]\n",
      "   [2.67733365e-01 2.17228785e-01 1.72467127e-01]\n",
      "   [2.21904188e-01 1.78715318e-01 1.29721522e-01]\n",
      "   ...\n",
      "   [2.20334843e-01 4.89858240e-01 4.88429874e-01]\n",
      "   [2.44635046e-01 5.28485775e-01 5.17091513e-01]\n",
      "   [2.20281765e-01 5.21323442e-01 4.97099578e-01]]]] [[0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 1 1]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 1 0]\n",
      " [0 1 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 1]\n",
      " [0 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "(50, 100, 100, 3) (50, 5)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(d_cls.train_gen)\n",
    "print(x, y)\n",
    "print(x.shape, y.shape)\n",
    "#from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples\n",
      "Epoch 1/2\n",
      "  32/1600 [..............................] - ETA: 11s"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    528\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1270\u001b[0m           \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1271\u001b[1;33m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[0;32m   1272\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype int64 for Tensor with dtype float32: <tf.Tensor 'loss/pred_loss/Cast:0' shape=(32, 5) dtype=float32>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-526e7c1918b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[1;32m---> 73\u001b[1;33m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[0;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[1;32m--> 760\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1786\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2132\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reduction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m           \u001b[0mper_sample_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m           weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[0;32m    168\u001b[0m               \u001b[0mper_sample_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[0;32m    220\u001b[0m           y_pred, y_true)\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\model\\tf_multi_loss.py\u001b[0m in \u001b[0;36mmasked_loss_function\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m#print(y_true, y_pred, mask, mask_value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmasked_loss_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6699\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6700\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6701\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   6702\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6703\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    561\u001b[0m                   \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[1;32m--> 563\u001b[1;33m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m       shuffle=shuffle)\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mconvert_to_generator_like\u001b[1;34m(data, batch_size, steps_per_epoch, epochs, shuffle)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m   \u001b[1;31m# Create generator from NumPy or EagerTensor Input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m   \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     raise ValueError(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(d_cls.train_gen\n",
    "                    , steps_per_epoch=d_cls.train_steps_per_epoch()\n",
    "                    , epochs=epochs\n",
    "                    , validation_data=d_cls.valid_gen\n",
    "                    , validation_steps=d_cls.valid_steps_per_epoch()\n",
    "                    , callbacks=cb\n",
    "                    , verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'D:\\\\work\\\\kaggle_data\\\\tf_multi_label_test\\\\tsv_logger.tsv' does not exist: b'D:\\\\work\\\\kaggle_data\\\\tf_multi_label_test\\\\tsv_logger.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-479be6a6f4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#plot_log.plot_results(out_dir, os.path.join(out_dir, 'history.tsv'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplot_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tsv_logger.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\dataset\\plot_log.py\u001b[0m in \u001b[0;36mplot_results\u001b[1;34m(out_dir, hist_file, acc_metric)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;34m\"\"\"\"CSVLogger で出した学習の損失関数と推測確率のファイルをplotする\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# カンマ区切りならpd.read_csv(hist_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# loss plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'D:\\\\work\\\\kaggle_data\\\\tf_multi_label_test\\\\tsv_logger.tsv' does not exist: b'D:\\\\work\\\\kaggle_data\\\\tf_multi_label_test\\\\tsv_logger.tsv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "#Jupyterでインライン表示するための宣言\n",
    "%matplotlib inline\n",
    "#plot_log.plot_results(out_dir, os.path.join(out_dir, 'history.tsv'))\n",
    "plot_log.plot_results(out_dir, os.path.join(out_dir, 'tsv_logger.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test set（今回はtest set なし）\n",
    "- タスクごとの混同行列とROC図も作成し、./< out_dir >/predict/test ディレクトリに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "## -------- 推論 --------\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "#\n",
    "## 推論結果出力先\n",
    "#out_predict_dir = os.path.join(out_dir, 'predict/test')\n",
    "#\n",
    "## 出力層のニューラルネットワークに分岐がない場合のpredict\n",
    "#y_test_list, y_pred_list = multi_predict.no_branch_set_predict(model, d_cls.X_test, d_cls.y_test, out_predict_dir)\n",
    "#\n",
    "## -------- 混同行列 --------\n",
    "## 分類クラス 0(negative), 1(positive), -1(ラベル欠損)\n",
    "#classes = [0,1,-1]\n",
    "#\n",
    "## タスクごとのpredictのスコア(y_pred)と正解ラベル(y_true)から混同行列をファイル出力\n",
    "#conf_matrix.binary_multi_confmx(classes, y_test_list, y_pred_list, out_predict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## -------- ROC_AUC --------\n",
    "## タスクごとのpredictのスコア(y_pred)と正解ラベル(y_true)からROC_AUCファイル出力\n",
    "#roc_curve.plot_roc(os.path.join(out_predict_dir, 'ROC_curve.png'), y_test_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### test set GradCam\n",
    "- GradCam実行した画像は./< out_dir >/grad_cam/ ディレクトリに出力\n",
    "\n",
    "#### ためしに1件実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_learning_phase(0) #Test時には0にセット modelロード前にこれがないとGradCamエラーになる\n",
    "#\n",
    "## GradCam出力先\n",
    "#out_grad_cam_dir = os.path.join(out_dir, 'grad_cam/test')\n",
    "#\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "#\n",
    "## 3次元numpy.array型の画像データ（*1./255.前）\n",
    "#x = d_cls.X_test[0]*255.0\n",
    "#input_img_name = 'test0'\n",
    "#\n",
    "#y_true = d_cls.y_test[0]\n",
    "#\n",
    "## 1画像について各タスクのGradCamを計算\n",
    "#grad_cam.nobranch_multi_grad_cam(model, out_grad_cam_dir, input_img_name, x, y_true, layer_name, shape[0], shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set 全件GradCam実行（十数時間かかる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#K.set_learning_phase(0) #Test時には0にセット modelロード前にこれがないとGradCamエラーになる\n",
    "#\n",
    "## GradCam出力先\n",
    "#out_grad_cam_dir = os.path.join(out_dir, 'grad_cam/test_all')\n",
    "#\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "#\n",
    "#for i,  x in enumerate(d_cls.X_test):\n",
    "#    # 3次元numpy.array型の画像データ（*1./255.前）\n",
    "#    x = x*255.0\n",
    "#\n",
    "#    # ファイル名\n",
    "#    file_path = test_files[test_files.index[i]]# test_filesはindexが0始まりではないので.index[i]で要素アクセス\n",
    "#    input_img_name = os.path.basename(file_path)\n",
    "#    print('input_img_name:', input_img_name)\n",
    "#    \n",
    "#    # 正解ラベル\n",
    "#    y_true = d_cls.y_test[i]\n",
    "#\n",
    "#    # 1画像について各タスクのGradCamを計算\n",
    "#    grad_cam_img = grad_cam.nobranch_multi_grad_cam(model, out_grad_cam_dir, input_img_name, x, y_true, layer_name, shape[0], shape[1])\n",
    "#\n",
    "## 確認用に1枚表示\n",
    "#plt.figure(figsize=(6, 4))\n",
    "#plt.imshow(grad_cam_img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_EfficientNetB3_path = os.path.join(out_dir, 'best_model.h5')\n",
    "model, orig_model = define_model.get_fine_tuning_model(out_dir, shape[0], shape[1], shape[2], num_classes\n",
    "                                                        , choice_model, trainable\n",
    "                                                        , fcs=fcs\n",
    "                                                        , fcpool=fcpool\n",
    "                                                        , drop=drop, is_add_batchnorm=is_add_batchnorm, kernel_init=kernel_init, l2_rate=l2_rate\n",
    "                                                        , pred_kernel_initializer=pred_kernel_initializer, pred_l2_rate=pred_l2_rate\n",
    "                                                        , activation=activation \n",
    "                                                        , gpu_count=gpu_count\n",
    "                                                        #, skip_bn=skip_bn\n",
    "                                                        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_EfficientNetB3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### validation set\n",
    "- タスクごとの混同行列とROC図も作成し、./< out_dir >/predict/validation ディレクトリに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# -------- 推論 --------\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "\n",
    "# 推論結果出力先\n",
    "out_predict_dir = os.path.join(out_dir, 'predict/validation')\n",
    "\n",
    "# 出力層のニューラルネットワークに分岐がない場合のpredict\n",
    "y_valid_list, y_pred_list = base_predict.no_branch_set_predict(model, d_cls.X_valid, d_cls.y_valid, out_predict_dir)\n",
    "\n",
    "# -------- 混同行列 --------\n",
    "# 分類クラス 0(negative), 1(positive), -1(ラベル欠損)\n",
    "classes = [0,1,-1]\n",
    "\n",
    "# タスクごとのpredictのスコア(y_pred)と正解ラベル(y_true)から混同行列をファイル出力\n",
    "conf_matrix.binary_multi_confmx(classes, y_valid_list, y_pred_list, out_predict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- ROC_AUC --------\n",
    "# タスクごとのpredictのスコア(y_pred)と正解ラベル(y_true)からROC_AUCファイル出力\n",
    "roc_curve.plot_roc(os.path.join(out_predict_dir, 'ROC_curve.png'), y_valid_list, y_pred_list\n",
    "                  , task_name_list=task_name_list\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation set GradCam\n",
    "- GradCam実行した画像は./< out_dir >/grad_cam/ ディレクトリに出力\n",
    "\n",
    "#### ためしに1件実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0993780ed8d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 1画像について各タスクのGradCamを計算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'top_activation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnobranch_multi_grad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_grad_cam_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_img_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\predicter\\tf_grad_cam.py\u001b[0m in \u001b[0;36mnobranch_multi_grad_cam\u001b[1;34m(model, out_grad_cam_dir, input_img_name, x, y_true, layer_name, img_rows, img_cols, pred_threshold, grad_threshold, is_gradcam_plus, predicted_score, run_gradcam_task_idx_list)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mjetcam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_cam_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mjetcam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[0mgrad_cam_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjetcam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\02_keras_py\\predicter\\tf_grad_cam.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[1;34m(model, X, x, layer_name, img_rows, img_cols, class_output)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# 勾配を取得\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mconv_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m   \u001b[1;31m# layer_nameのレイヤーのアウトプット\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# gradients(loss, variables) で、variablesのlossに関しての勾配を返す\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mgradient_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# model.inputを入力すると、conv_outputとgradsを出力する関数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3795\u001b[0m   \"\"\"\n\u001b[0;32m   3796\u001b[0m   return gradients_module.gradients(\n\u001b[1;32m-> 3797\u001b[1;33m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[0;32m   3798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    159\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu20\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    503\u001b[0m   \u001b[1;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[0;32m    506\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[0;32m    507\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "#K.set_learning_phase(0) #Test時には0にセット modelロード前にこれがないとGradCamエラーになる\n",
    "\n",
    "# GradCam出力先\n",
    "out_grad_cam_dir = os.path.join(out_dir, 'grad_cam/validation')\n",
    "\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "# Custom Functionを使ったmodelを別環境で使用するには、modelをロードする際に引数として、[custom_objects]を指定するがある\n",
    "# https://qiita.com/tkinjo1/items/51f9e2d0d9c4659bde8a\n",
    "#model = keras.models.load_model(os.path.join(output_dir, 'finetuning.h5'), custom_objects={'lr':lr_metric})\n",
    "\n",
    "# 3次元numpy.array型の画像データ（*1./255.前）\n",
    "x = d_cls.X_valid[0]*255.0\n",
    "input_img_name = 'valid0'\n",
    "\n",
    "y_true = d_cls.y_valid[0]\n",
    "\n",
    "# 1画像について各タスクのGradCamを計算\n",
    "layer_name = 'top_activation'\n",
    "grad_cam.nobranch_multi_grad_cam(model, out_grad_cam_dir, input_img_name, x, y_true, layer_name, shape[0], shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation set 全件GradCam実行（数時間かかる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_files' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#K.set_learning_phase(0) #Test時には0にセット modelロード前にこれがないとGradCamエラーになる\n",
    "\n",
    "# GradCam出力先\n",
    "out_grad_cam_dir = os.path.join(out_dir, 'grad_cam/validation_all')\n",
    "\n",
    "#model = keras.models.load_model(os.path.join(out_dir, 'best_model.h5'), compile=False)\n",
    "\n",
    "for i,  x in enumerate(d_cls.X_valid):\n",
    "    # 3次元numpy.array型の画像データ（*1./255.前）\n",
    "    x = x*255.0\n",
    "    \n",
    "    # ファイル名\n",
    "    file_path = validation_files[validation_files.index[i]]# validation_filesはindexが0始まりではないので.index[i]で要素アクセス\n",
    "    input_img_name = os.path.basename(file_path)\n",
    "    print('input_img_name:', input_img_name)\n",
    "    \n",
    "    # 正解ラベル\n",
    "    y_true = d_cls.y_valid[i]\n",
    "\n",
    "    # 1画像について各タスクのGradCamを計算\n",
    "    grad_cam_img = grad_cam.nobranch_multi_grad_cam(model, out_grad_cam_dir, input_img_name, x, y_true, layer_name, shape[0], shape[1])\n",
    "\n",
    "# 確認用に1枚表示\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(grad_cam_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
